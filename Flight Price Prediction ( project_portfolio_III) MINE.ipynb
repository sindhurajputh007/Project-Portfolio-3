{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9e4c049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "84b1c660",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Train.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "72bf9ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date_of_Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep_Time</th>\n",
       "      <th>Arrival_Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Additional_Info</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>24/03/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR → DEL</td>\n",
       "      <td>22:20</td>\n",
       "      <td>01:10 22 Mar</td>\n",
       "      <td>2h 50m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>3897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air India</td>\n",
       "      <td>1/05/2019</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU → IXR → BBI → BLR</td>\n",
       "      <td>05:50</td>\n",
       "      <td>13:15</td>\n",
       "      <td>7h 25m</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>7662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>9/06/2019</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL → LKO → BOM → COK</td>\n",
       "      <td>09:25</td>\n",
       "      <td>04:25 10 Jun</td>\n",
       "      <td>19h</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>13882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>12/05/2019</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU → NAG → BLR</td>\n",
       "      <td>18:05</td>\n",
       "      <td>23:30</td>\n",
       "      <td>5h 25m</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>6218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>01/03/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR → NAG → DEL</td>\n",
       "      <td>16:50</td>\n",
       "      <td>21:35</td>\n",
       "      <td>4h 45m</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>13302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10678</th>\n",
       "      <td>Air Asia</td>\n",
       "      <td>9/04/2019</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU → BLR</td>\n",
       "      <td>19:55</td>\n",
       "      <td>22:25</td>\n",
       "      <td>2h 30m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>4107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10679</th>\n",
       "      <td>Air India</td>\n",
       "      <td>27/04/2019</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU → BLR</td>\n",
       "      <td>20:45</td>\n",
       "      <td>23:20</td>\n",
       "      <td>2h 35m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>4145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10680</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>27/04/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>BLR → DEL</td>\n",
       "      <td>08:20</td>\n",
       "      <td>11:20</td>\n",
       "      <td>3h</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>7229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10681</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>01/03/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR → DEL</td>\n",
       "      <td>11:30</td>\n",
       "      <td>14:10</td>\n",
       "      <td>2h 40m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>12648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10682</th>\n",
       "      <td>Air India</td>\n",
       "      <td>9/05/2019</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL → GOI → BOM → COK</td>\n",
       "      <td>10:55</td>\n",
       "      <td>19:15</td>\n",
       "      <td>8h 20m</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>11753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10683 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Airline Date_of_Journey    Source Destination  \\\n",
       "0           IndiGo      24/03/2019  Banglore   New Delhi   \n",
       "1        Air India       1/05/2019   Kolkata    Banglore   \n",
       "2      Jet Airways       9/06/2019     Delhi      Cochin   \n",
       "3           IndiGo      12/05/2019   Kolkata    Banglore   \n",
       "4           IndiGo      01/03/2019  Banglore   New Delhi   \n",
       "...            ...             ...       ...         ...   \n",
       "10678     Air Asia       9/04/2019   Kolkata    Banglore   \n",
       "10679    Air India      27/04/2019   Kolkata    Banglore   \n",
       "10680  Jet Airways      27/04/2019  Banglore       Delhi   \n",
       "10681      Vistara      01/03/2019  Banglore   New Delhi   \n",
       "10682    Air India       9/05/2019     Delhi      Cochin   \n",
       "\n",
       "                       Route Dep_Time  Arrival_Time Duration Total_Stops  \\\n",
       "0                  BLR → DEL    22:20  01:10 22 Mar   2h 50m    non-stop   \n",
       "1      CCU → IXR → BBI → BLR    05:50         13:15   7h 25m     2 stops   \n",
       "2      DEL → LKO → BOM → COK    09:25  04:25 10 Jun      19h     2 stops   \n",
       "3            CCU → NAG → BLR    18:05         23:30   5h 25m      1 stop   \n",
       "4            BLR → NAG → DEL    16:50         21:35   4h 45m      1 stop   \n",
       "...                      ...      ...           ...      ...         ...   \n",
       "10678              CCU → BLR    19:55         22:25   2h 30m    non-stop   \n",
       "10679              CCU → BLR    20:45         23:20   2h 35m    non-stop   \n",
       "10680              BLR → DEL    08:20         11:20       3h    non-stop   \n",
       "10681              BLR → DEL    11:30         14:10   2h 40m    non-stop   \n",
       "10682  DEL → GOI → BOM → COK    10:55         19:15   8h 20m     2 stops   \n",
       "\n",
       "      Additional_Info  Price  \n",
       "0             No info   3897  \n",
       "1             No info   7662  \n",
       "2             No info  13882  \n",
       "3             No info   6218  \n",
       "4             No info  13302  \n",
       "...               ...    ...  \n",
       "10678         No info   4107  \n",
       "10679         No info   4145  \n",
       "10680         No info   7229  \n",
       "10681         No info  12648  \n",
       "10682         No info  11753  \n",
       "\n",
       "[10683 rows x 11 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e577d751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10683 entries, 0 to 10682\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Airline          10683 non-null  object\n",
      " 1   Date_of_Journey  10683 non-null  object\n",
      " 2   Source           10683 non-null  object\n",
      " 3   Destination      10683 non-null  object\n",
      " 4   Route            10682 non-null  object\n",
      " 5   Dep_Time         10683 non-null  object\n",
      " 6   Arrival_Time     10683 non-null  object\n",
      " 7   Duration         10683 non-null  object\n",
      " 8   Total_Stops      10682 non-null  object\n",
      " 9   Additional_Info  10683 non-null  object\n",
      " 10  Price            10683 non-null  int64 \n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 918.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "811de609",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare proposal document and final presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d8cac749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question:\n",
    "## 5w and h ## \n",
    "# 1. Which airline is most preffered airline.\n",
    "# 2. Mean/Median price for which airline is highest and lowest.\n",
    "# 3. For each flight which is the most common source and destination airport.\n",
    "# 4. How many flights are going from each source airports and destination airport.\n",
    "# 5. Which airline is having most non-stop flight.\n",
    "# 6. Which day of week we have maximum and minimum flights?\n",
    "# 7. During what time day we have more flights?\n",
    "# 8. What is the average price for flights on each day of week?\n",
    "#      a. Different hours of day [morning/afternoon/evening/night] what is the average price?\n",
    "# 9. How price and duration of flight is varring?\n",
    "# 10. For which source and destiantion you have maximum and minimum duration?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac81a14",
   "metadata": {},
   "source": [
    "# Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "543d1b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicate data\n",
    "# Date of Jorney is object need to be converted into Datetime.\n",
    "# Dep_Time is fine.\n",
    "# Arrival Time is incorrectly placed so need to fixed.\n",
    "# Duration is available in HH:MM format need to be either in minutes or hours. checked\n",
    "# Total_Stops should be numerical but right it is object.\n",
    "# Check if Additional_Info column provides any meaning information or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8953ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop Duplicates\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "536ba84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_minute(duration):\n",
    "    dur = duration.split()\n",
    "    min = 0\n",
    "    for x in dur:\n",
    "        if x[-1] == 'h':\n",
    "            min = min + int(x[:-1])*60\n",
    "\n",
    "        if x[-1] == 'm':\n",
    "            min = min + int(int(x[:-1])) \n",
    "    return min\n",
    "\n",
    "def convert_duration_to_minutes(time):\n",
    "    '''\n",
    "    This function converts duration in h m to minutes:\n",
    "    input : hh:mm ,hh, mm\n",
    "    return:\n",
    "        min\n",
    "    '''\n",
    "    if len(time.split(' ')) >1 :\n",
    "        hh,mm = time.split(' ')\n",
    "        hh,mm = int(hh[:-1]),int(mm[:-1])\n",
    "        duration = hh*60+mm\n",
    "    else:\n",
    "        if 'h' in time:\n",
    "            duration = int(time[:-1])*60\n",
    "        else:\n",
    "            duration= int(time[:-1])\n",
    "            \n",
    "    return duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4f996dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_2348\\2267467950.py:12: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df['DepartureDateTime'] = pd.to_datetime(df['DepartureDateTime'],infer_datetime_format=True)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_2348\\2267467950.py:12: UserWarning: Parsing dates in %d/%m/%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df['DepartureDateTime'] = pd.to_datetime(df['DepartureDateTime'],infer_datetime_format=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date_of_Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep_Time</th>\n",
       "      <th>Arrival_Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Additional_Info</th>\n",
       "      <th>Price</th>\n",
       "      <th>DepartureDateTime</th>\n",
       "      <th>Duration_min</th>\n",
       "      <th>Duration_timedelta</th>\n",
       "      <th>ArrivalDateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>24/03/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR → DEL</td>\n",
       "      <td>22:20</td>\n",
       "      <td>01:10 22 Mar</td>\n",
       "      <td>2h 50m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>3897</td>\n",
       "      <td>2019-03-24 22:20:00</td>\n",
       "      <td>170</td>\n",
       "      <td>0 days 02:50:00</td>\n",
       "      <td>2019-03-25 01:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air India</td>\n",
       "      <td>1/05/2019</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU → IXR → BBI → BLR</td>\n",
       "      <td>05:50</td>\n",
       "      <td>13:15</td>\n",
       "      <td>7h 25m</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>7662</td>\n",
       "      <td>2019-05-01 05:50:00</td>\n",
       "      <td>445</td>\n",
       "      <td>0 days 07:25:00</td>\n",
       "      <td>2019-05-01 13:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>9/06/2019</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL → LKO → BOM → COK</td>\n",
       "      <td>09:25</td>\n",
       "      <td>04:25 10 Jun</td>\n",
       "      <td>19h</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>13882</td>\n",
       "      <td>2019-06-09 09:25:00</td>\n",
       "      <td>1140</td>\n",
       "      <td>0 days 19:00:00</td>\n",
       "      <td>2019-06-10 04:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>12/05/2019</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU → NAG → BLR</td>\n",
       "      <td>18:05</td>\n",
       "      <td>23:30</td>\n",
       "      <td>5h 25m</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>6218</td>\n",
       "      <td>2019-05-12 18:05:00</td>\n",
       "      <td>325</td>\n",
       "      <td>0 days 05:25:00</td>\n",
       "      <td>2019-05-12 23:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>01/03/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR → NAG → DEL</td>\n",
       "      <td>16:50</td>\n",
       "      <td>21:35</td>\n",
       "      <td>4h 45m</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>13302</td>\n",
       "      <td>2019-03-01 16:50:00</td>\n",
       "      <td>285</td>\n",
       "      <td>0 days 04:45:00</td>\n",
       "      <td>2019-03-01 21:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10678</th>\n",
       "      <td>Air Asia</td>\n",
       "      <td>9/04/2019</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU → BLR</td>\n",
       "      <td>19:55</td>\n",
       "      <td>22:25</td>\n",
       "      <td>2h 30m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>4107</td>\n",
       "      <td>2019-04-09 19:55:00</td>\n",
       "      <td>150</td>\n",
       "      <td>0 days 02:30:00</td>\n",
       "      <td>2019-04-09 22:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10679</th>\n",
       "      <td>Air India</td>\n",
       "      <td>27/04/2019</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU → BLR</td>\n",
       "      <td>20:45</td>\n",
       "      <td>23:20</td>\n",
       "      <td>2h 35m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>4145</td>\n",
       "      <td>2019-04-27 20:45:00</td>\n",
       "      <td>155</td>\n",
       "      <td>0 days 02:35:00</td>\n",
       "      <td>2019-04-27 23:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10680</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>27/04/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>BLR → DEL</td>\n",
       "      <td>08:20</td>\n",
       "      <td>11:20</td>\n",
       "      <td>3h</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>7229</td>\n",
       "      <td>2019-04-27 08:20:00</td>\n",
       "      <td>180</td>\n",
       "      <td>0 days 03:00:00</td>\n",
       "      <td>2019-04-27 11:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10681</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>01/03/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR → DEL</td>\n",
       "      <td>11:30</td>\n",
       "      <td>14:10</td>\n",
       "      <td>2h 40m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>12648</td>\n",
       "      <td>2019-03-01 11:30:00</td>\n",
       "      <td>160</td>\n",
       "      <td>0 days 02:40:00</td>\n",
       "      <td>2019-03-01 14:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10682</th>\n",
       "      <td>Air India</td>\n",
       "      <td>9/05/2019</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL → GOI → BOM → COK</td>\n",
       "      <td>10:55</td>\n",
       "      <td>19:15</td>\n",
       "      <td>8h 20m</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>11753</td>\n",
       "      <td>2019-05-09 10:55:00</td>\n",
       "      <td>500</td>\n",
       "      <td>0 days 08:20:00</td>\n",
       "      <td>2019-05-09 19:15:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10463 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Airline Date_of_Journey    Source Destination  \\\n",
       "0           IndiGo      24/03/2019  Banglore   New Delhi   \n",
       "1        Air India       1/05/2019   Kolkata    Banglore   \n",
       "2      Jet Airways       9/06/2019     Delhi      Cochin   \n",
       "3           IndiGo      12/05/2019   Kolkata    Banglore   \n",
       "4           IndiGo      01/03/2019  Banglore   New Delhi   \n",
       "...            ...             ...       ...         ...   \n",
       "10678     Air Asia       9/04/2019   Kolkata    Banglore   \n",
       "10679    Air India      27/04/2019   Kolkata    Banglore   \n",
       "10680  Jet Airways      27/04/2019  Banglore       Delhi   \n",
       "10681      Vistara      01/03/2019  Banglore   New Delhi   \n",
       "10682    Air India       9/05/2019     Delhi      Cochin   \n",
       "\n",
       "                       Route Dep_Time  Arrival_Time Duration Total_Stops  \\\n",
       "0                  BLR → DEL    22:20  01:10 22 Mar   2h 50m    non-stop   \n",
       "1      CCU → IXR → BBI → BLR    05:50         13:15   7h 25m     2 stops   \n",
       "2      DEL → LKO → BOM → COK    09:25  04:25 10 Jun      19h     2 stops   \n",
       "3            CCU → NAG → BLR    18:05         23:30   5h 25m      1 stop   \n",
       "4            BLR → NAG → DEL    16:50         21:35   4h 45m      1 stop   \n",
       "...                      ...      ...           ...      ...         ...   \n",
       "10678              CCU → BLR    19:55         22:25   2h 30m    non-stop   \n",
       "10679              CCU → BLR    20:45         23:20   2h 35m    non-stop   \n",
       "10680              BLR → DEL    08:20         11:20       3h    non-stop   \n",
       "10681              BLR → DEL    11:30         14:10   2h 40m    non-stop   \n",
       "10682  DEL → GOI → BOM → COK    10:55         19:15   8h 20m     2 stops   \n",
       "\n",
       "      Additional_Info  Price   DepartureDateTime  Duration_min  \\\n",
       "0             No info   3897 2019-03-24 22:20:00           170   \n",
       "1             No info   7662 2019-05-01 05:50:00           445   \n",
       "2             No info  13882 2019-06-09 09:25:00          1140   \n",
       "3             No info   6218 2019-05-12 18:05:00           325   \n",
       "4             No info  13302 2019-03-01 16:50:00           285   \n",
       "...               ...    ...                 ...           ...   \n",
       "10678         No info   4107 2019-04-09 19:55:00           150   \n",
       "10679         No info   4145 2019-04-27 20:45:00           155   \n",
       "10680         No info   7229 2019-04-27 08:20:00           180   \n",
       "10681         No info  12648 2019-03-01 11:30:00           160   \n",
       "10682         No info  11753 2019-05-09 10:55:00           500   \n",
       "\n",
       "      Duration_timedelta     ArrivalDateTime  \n",
       "0        0 days 02:50:00 2019-03-25 01:10:00  \n",
       "1        0 days 07:25:00 2019-05-01 13:15:00  \n",
       "2        0 days 19:00:00 2019-06-10 04:25:00  \n",
       "3        0 days 05:25:00 2019-05-12 23:30:00  \n",
       "4        0 days 04:45:00 2019-03-01 21:35:00  \n",
       "...                  ...                 ...  \n",
       "10678    0 days 02:30:00 2019-04-09 22:25:00  \n",
       "10679    0 days 02:35:00 2019-04-27 23:20:00  \n",
       "10680    0 days 03:00:00 2019-04-27 11:20:00  \n",
       "10681    0 days 02:40:00 2019-03-01 14:10:00  \n",
       "10682    0 days 08:20:00 2019-05-09 19:15:00  \n",
       "\n",
       "[10463 rows x 15 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['DepartureDateTime'] = df['Date_of_Journey'] + \" \"+ df['Dep_Time']\n",
    "# df['DepartureDateTime'] = pd.to_datetime(df['DepartureDateTime'],infer_datetime_format=True)\n",
    "# df['Duration_min'] = df['Duration'].apply(lambda x: convert_duration_to_minutes(x))\n",
    "# df['Duration_timedelta'] = pd.to_timedelta(df['Duration_min'], unit='m')\n",
    "# df[\"ArrivalDateTime\"] = df['DepartureDateTime'] + df['Duration_timedelta']\n",
    "\n",
    "def create_arrival_time(df):\n",
    "    '''\n",
    "    This Function preprocess date_of_journey and duration to create departure and arrival date time.\n",
    "    '''\n",
    "    df['DepartureDateTime'] = df['Date_of_Journey'] + \" \"+ df['Dep_Time']\n",
    "    df['DepartureDateTime'] = pd.to_datetime(df['DepartureDateTime'],infer_datetime_format=True)\n",
    "    df['Duration_min'] = df['Duration'].apply(lambda x: convert_duration_to_minutes(x))\n",
    "    df['Duration_timedelta'] = pd.to_timedelta(df['Duration_min'], unit='m')\n",
    "    df[\"ArrivalDateTime\"] = df['DepartureDateTime'] + df['Duration_timedelta']\n",
    "    return df\n",
    "\n",
    "create_arrival_time(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3510733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Date_of_Journey','Dep_Time','Arrival_Time','Duration'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8dd91865",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_dict = {\n",
    "    'non-stop':0,\n",
    "    '2 stops':2,\n",
    "    '1 stop':1,\n",
    "    '3 stops':3,\n",
    "    '4 stops':4\n",
    "}\n",
    "df['Total_Stops'] = df['Total_Stops'].replace(stops_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3d6198a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Additional_Info\n",
       "No info                         78.208927\n",
       "In-flight meal not included     18.407722\n",
       "No check-in baggage included     3.039281\n",
       "1 Long layover                   0.181592\n",
       "Change airports                  0.066902\n",
       "Business class                   0.038230\n",
       "No Info                          0.028672\n",
       "1 Short layover                  0.009557\n",
       "Red-eye flight                   0.009557\n",
       "2 Long layover                   0.009557\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Additional_Info'].value_counts()/len(df)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6f2b8443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional Info columns doesnot have any meaningful information.\n",
    "df.drop(columns=['Additional_Info'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f848610a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Price</th>\n",
       "      <th>DepartureDateTime</th>\n",
       "      <th>Duration_min</th>\n",
       "      <th>Duration_timedelta</th>\n",
       "      <th>ArrivalDateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR → DEL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3897</td>\n",
       "      <td>2019-03-24 22:20:00</td>\n",
       "      <td>170</td>\n",
       "      <td>0 days 02:50:00</td>\n",
       "      <td>2019-03-25 01:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air India</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU → IXR → BBI → BLR</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7662</td>\n",
       "      <td>2019-05-01 05:50:00</td>\n",
       "      <td>445</td>\n",
       "      <td>0 days 07:25:00</td>\n",
       "      <td>2019-05-01 13:15:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Airline    Source Destination                  Route  Total_Stops  Price  \\\n",
       "0     IndiGo  Banglore   New Delhi              BLR → DEL          0.0   3897   \n",
       "1  Air India   Kolkata    Banglore  CCU → IXR → BBI → BLR          2.0   7662   \n",
       "\n",
       "    DepartureDateTime  Duration_min Duration_timedelta     ArrivalDateTime  \n",
       "0 2019-03-24 22:20:00           170    0 days 02:50:00 2019-03-25 01:10:00  \n",
       "1 2019-05-01 05:50:00           445    0 days 07:25:00 2019-05-01 13:15:00  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edd5863",
   "metadata": {},
   "source": [
    "#### Actions on Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0fcc4010",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Date_of_Journey'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Date_of_Journey'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 66\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m## process for training    \u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m sanity_check(df)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# process of prediction\u001b[39;00m\n\u001b[0;32m     68\u001b[0m sanity_check(df,train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[63], line 59\u001b[0m, in \u001b[0;36msanity_check\u001b[1;34m(df, train)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train:\n\u001b[0;32m     57\u001b[0m     df\u001b[38;5;241m.\u001b[39mdrop_duplicates(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 59\u001b[0m create_preprocess_date_time(df)\n\u001b[0;32m     60\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal_Stops\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal_Stops\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(stops_dict)\n\u001b[0;32m     61\u001b[0m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate_of_Journey\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDep_Time\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArrival_Time\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDuration\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdditional_Info\u001b[39m\u001b[38;5;124m'\u001b[39m],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[63], line 25\u001b[0m, in \u001b[0;36mcreate_preprocess_date_time\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_preprocess_date_time\u001b[39m(df):\n\u001b[0;32m     22\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03m    This Function preprocess date_of_journey and duration to create departure and arrival date time.\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDepartureDateTime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate_of_Journey\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDep_Time\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     26\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDepartureDateTime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDepartureDateTime\u001b[39m\u001b[38;5;124m'\u001b[39m],infer_datetime_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     27\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDuration_min\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDuration\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: convert_duration_to_minutes(x))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Date_of_Journey'"
     ]
    }
   ],
   "source": [
    "def convert_duration_to_minutes(time):\n",
    "    '''\n",
    "    This function converts duration in h m to minutes:\n",
    "    input : hh:mm ,hh, mm\n",
    "    return:\n",
    "        min\n",
    "    '''\n",
    "    if len(time.split(' ')) >1 :\n",
    "        hh,mm = time.split(' ')\n",
    "        hh,mm = int(hh[:-1]),int(mm[:-1])\n",
    "        duration = hh*60+mm\n",
    "    else:\n",
    "        if 'h' in time:\n",
    "            duration = int(time[:-1])*60\n",
    "        else:\n",
    "            duration= int(time[:-1])\n",
    "            \n",
    "    return duration\n",
    "\n",
    "\n",
    "def create_preprocess_date_time(df):\n",
    "    '''\n",
    "    This Function preprocess date_of_journey and duration to create departure and arrival date time.\n",
    "    '''\n",
    "    df['DepartureDateTime'] = df['Date_of_Journey'] + \" \"+ df['Dep_Time']\n",
    "    df['DepartureDateTime'] = pd.to_datetime(df['DepartureDateTime'],infer_datetime_format=True)\n",
    "    df['Duration_min'] = df['Duration'].apply(lambda x: convert_duration_to_minutes(x))\n",
    "    df['Duration_timedelta'] = pd.to_timedelta(df['Duration_min'], unit='m')\n",
    "    df[\"ArrivalDateTime\"] = df['DepartureDateTime'] + df['Duration_timedelta']\n",
    "    return df\n",
    "\n",
    "stops_dict = {\n",
    "    'non-stop':0,\n",
    "    '2 stops':2,\n",
    "    '1 stop':1,\n",
    "    '3 stops':3,\n",
    "    '4 stops':4\n",
    "}\n",
    "\n",
    "## Running the process of prediction is also referred as inference:\n",
    "def sanity_check(df,train=True):\n",
    "    '''\n",
    "    This function performs sanity check on the airline data.\n",
    "    inputs:\n",
    "        df: dataframe that we need to perform sanity check\n",
    "        train: This is used for process of training and inference.\n",
    "            train is having default value of True and can be set as False if we are running inference.\n",
    "            \n",
    "        ## process for training    \n",
    "        sanity_check(df)\n",
    "        # process of prediction\n",
    "        sanity_check(df,train=False)\n",
    "    returns:\n",
    "        df\n",
    "    '''\n",
    "    if train:\n",
    "        df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    create_preprocess_date_time(df)\n",
    "    df['Total_Stops'] = df['Total_Stops'].replace(stops_dict)\n",
    "    df.drop(columns=['Date_of_Journey','Dep_Time','Arrival_Time','Duration','Additional_Info'],axis=1,inplace=True)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "## process for training    \n",
    "sanity_check(df)\n",
    "# process of prediction\n",
    "sanity_check(df,train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebdaaff",
   "metadata": {},
   "source": [
    "# Missing value Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b35ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping Nan value as its a single observation.\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18ed007",
   "metadata": {},
   "source": [
    "#### Actions on missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ded5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_value(df,train=True):\n",
    "    \"\"\"\n",
    "    This function helps to handle missing value.\n",
    "    Since for Airline data there is just one missing value we can choose to drop missing value.\n",
    "    inputs:\n",
    "         df: dataframe which requires imputation.\n",
    "         \n",
    "    returns:\n",
    "        df\n",
    "    \n",
    "    \"\"\"\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "handle_missing_value(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d582a53",
   "metadata": {},
   "source": [
    "# Handling Categorical Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b3976372",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Destination'] = df['Destination'].replace({'New Delhi':'Delhi'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ae48503d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column : Airline  Unique values : ['IndiGo' 'Air India' 'Jet Airways' 'SpiceJet' 'Multiple carriers' 'GoAir'\n",
      " 'Vistara' 'Air Asia' 'Vistara Premium economy' 'Jet Airways Business'\n",
      " 'Multiple carriers Premium economy' 'Trujet']  and No. of uniques :  12\n",
      "------------------------------------------------------------------------------------------\n",
      "Column : Source  Unique values : ['Banglore' 'Kolkata' 'Delhi' 'Chennai' 'Mumbai']  and No. of uniques :  5\n",
      "------------------------------------------------------------------------------------------\n",
      "Column : Destination  Unique values : ['Delhi' 'Banglore' 'Cochin' 'Kolkata' 'Hyderabad']  and No. of uniques :  5\n",
      "------------------------------------------------------------------------------------------\n",
      "Column : Route  Unique values : ['BLR → DEL' 'CCU → IXR → BBI → BLR' 'DEL → LKO → BOM → COK'\n",
      " 'CCU → NAG → BLR' 'BLR → NAG → DEL' 'CCU → BLR' 'BLR → BOM → DEL'\n",
      " 'DEL → BOM → COK' 'DEL → BLR → COK' 'MAA → CCU' 'CCU → BOM → BLR'\n",
      " 'DEL → AMD → BOM → COK' 'DEL → PNQ → COK' 'DEL → CCU → BOM → COK'\n",
      " 'BLR → COK → DEL' 'DEL → IDR → BOM → COK' 'DEL → LKO → COK'\n",
      " 'CCU → GAU → DEL → BLR' 'DEL → NAG → BOM → COK' 'CCU → MAA → BLR'\n",
      " 'DEL → HYD → COK' 'CCU → HYD → BLR' 'DEL → COK' 'CCU → DEL → BLR'\n",
      " 'BLR → BOM → AMD → DEL' 'BOM → DEL → HYD' 'DEL → MAA → COK' 'BOM → HYD'\n",
      " 'DEL → BHO → BOM → COK' 'DEL → JAI → BOM → COK' 'DEL → ATQ → BOM → COK'\n",
      " 'DEL → JDH → BOM → COK' 'CCU → BBI → BOM → BLR' 'BLR → MAA → DEL'\n",
      " 'DEL → GOI → BOM → COK' 'DEL → BDQ → BOM → COK' 'CCU → JAI → BOM → BLR'\n",
      " 'CCU → BBI → BLR' 'BLR → HYD → DEL' 'DEL → TRV → COK'\n",
      " 'CCU → IXR → DEL → BLR' 'DEL → IXU → BOM → COK' 'CCU → IXB → BLR'\n",
      " 'BLR → BOM → JDH → DEL' 'DEL → UDR → BOM → COK' 'DEL → HYD → MAA → COK'\n",
      " 'CCU → BOM → COK → BLR' 'BLR → CCU → DEL' 'CCU → BOM → GOI → BLR'\n",
      " 'DEL → RPR → NAG → BOM → COK' 'DEL → HYD → BOM → COK'\n",
      " 'CCU → DEL → AMD → BLR' 'CCU → PNQ → BLR' 'BLR → CCU → GAU → DEL'\n",
      " 'CCU → DEL → COK → BLR' 'BLR → PNQ → DEL' 'BOM → JDH → DEL → HYD'\n",
      " 'BLR → BOM → BHO → DEL' 'DEL → AMD → COK' 'BLR → LKO → DEL'\n",
      " 'CCU → GAU → BLR' 'BOM → GOI → HYD' 'CCU → BOM → AMD → BLR'\n",
      " 'CCU → BBI → IXR → DEL → BLR' 'DEL → DED → BOM → COK'\n",
      " 'DEL → MAA → BOM → COK' 'BLR → AMD → DEL' 'BLR → VGA → DEL'\n",
      " 'CCU → JAI → DEL → BLR' 'CCU → AMD → BLR' 'CCU → VNS → DEL → BLR'\n",
      " 'BLR → BOM → IDR → DEL' 'BLR → BBI → DEL' 'BLR → GOI → DEL'\n",
      " 'BOM → AMD → ISK → HYD' 'BOM → DED → DEL → HYD' 'DEL → IXC → BOM → COK'\n",
      " 'CCU → PAT → BLR' 'BLR → CCU → BBI → DEL' 'CCU → BBI → HYD → BLR'\n",
      " 'BLR → BOM → NAG → DEL' 'BLR → CCU → BBI → HYD → DEL' 'BLR → GAU → DEL'\n",
      " 'BOM → BHO → DEL → HYD' 'BOM → JLR → HYD' 'BLR → HYD → VGA → DEL'\n",
      " 'CCU → KNU → BLR' 'CCU → BOM → PNQ → BLR' 'DEL → BBI → COK'\n",
      " 'BLR → VGA → HYD → DEL' 'BOM → JDH → JAI → DEL → HYD'\n",
      " 'DEL → GWL → IDR → BOM → COK' 'CCU → RPR → HYD → BLR' 'CCU → VTZ → BLR'\n",
      " 'CCU → DEL → VGA → BLR' 'BLR → BOM → IDR → GWL → DEL'\n",
      " 'CCU → DEL → COK → TRV → BLR' 'BOM → COK → MAA → HYD' 'BOM → NDC → HYD'\n",
      " 'BLR → BDQ → DEL' 'CCU → BOM → TRV → BLR' 'CCU → BOM → HBX → BLR'\n",
      " 'BOM → BDQ → DEL → HYD' 'BOM → CCU → HYD' 'BLR → TRV → COK → DEL'\n",
      " 'BLR → IDR → DEL' 'CCU → IXZ → MAA → BLR' 'CCU → GAU → IMF → DEL → BLR'\n",
      " 'BOM → GOI → PNQ → HYD' 'BOM → BLR → CCU → BBI → HYD' 'BOM → MAA → HYD'\n",
      " 'BLR → BOM → UDR → DEL' 'BOM → UDR → DEL → HYD' 'BLR → VGA → VTZ → DEL'\n",
      " 'BLR → HBX → BOM → BHO → DEL' 'CCU → IXA → BLR' 'BOM → RPR → VTZ → HYD'\n",
      " 'BLR → HBX → BOM → AMD → DEL' 'BOM → IDR → DEL → HYD' 'BOM → BLR → HYD'\n",
      " 'BLR → STV → DEL' 'CCU → IXB → DEL → BLR' 'BOM → JAI → DEL → HYD'\n",
      " 'BOM → VNS → DEL → HYD' 'BLR → HBX → BOM → NAG → DEL' nan\n",
      " 'BLR → BOM → IXC → DEL' 'BLR → CCU → BBI → HYD → VGA → DEL'\n",
      " 'BOM → BBI → HYD']  and No. of uniques :  128\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# No order in columns\n",
    "categorical_cols = ['Airline', 'Source', 'Destination', 'Route']\n",
    "for col in categorical_cols:\n",
    "    print(\"Column :\",col,\" Unique values :\",df[col].unique(),\" and No. of uniques : \",df[col].nunique())\n",
    "    print(\"-\"*90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6aced34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'Airline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0a5ce5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Airline\n",
       "Air Asia                              318\n",
       "Air India                            1695\n",
       "GoAir                                 194\n",
       "IndiGo                               2043\n",
       "Jet Airways                          3700\n",
       "Jet Airways Business                    6\n",
       "Multiple carriers                    1196\n",
       "Multiple carriers Premium economy      13\n",
       "SpiceJet                              815\n",
       "Trujet                                  1\n",
       "Vistara                               477\n",
       "Vistara Premium economy                 3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(col).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "eb77a9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_value = df.groupby(col).size()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b5d32b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Airline\n",
       "Air Asia                             0.030399\n",
       "Air India                            0.162030\n",
       "GoAir                                0.018545\n",
       "IndiGo                               0.195297\n",
       "Jet Airways                          0.353695\n",
       "Jet Airways Business                 0.000574\n",
       "Multiple carriers                    0.114329\n",
       "Multiple carriers Premium economy    0.001243\n",
       "SpiceJet                             0.077908\n",
       "Trujet                               0.000096\n",
       "Vistara                              0.045598\n",
       "Vistara Premium economy              0.000287\n",
       "dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7bdbb702",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dict = freq_value.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "507f06b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Air Asia': 0.030398623458560366,\n",
       " 'Air India': 0.16203039862345855,\n",
       " 'GoAir': 0.018545072172832425,\n",
       " 'IndiGo': 0.19529681674792085,\n",
       " 'Jet Airways': 0.35369467546123695,\n",
       " 'Jet Airways Business': 0.0005735589331803843,\n",
       " 'Multiple carriers': 0.1143294140139566,\n",
       " 'Multiple carriers Premium economy': 0.0012427110218908325,\n",
       " 'SpiceJet': 0.0779084217570022,\n",
       " 'Trujet': 9.559315553006405e-05,\n",
       " 'Vistara': 0.04559793518784055,\n",
       " 'Vistara Premium economy': 0.00028677946659019213}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "288007f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Freq_encoded_\"+col] = df[col].replace(freq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e3b3b2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Price</th>\n",
       "      <th>DepartureDateTime</th>\n",
       "      <th>Duration_min</th>\n",
       "      <th>Duration_timedelta</th>\n",
       "      <th>ArrivalDateTime</th>\n",
       "      <th>Freq_encoded_Airline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>BLR → DEL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3897</td>\n",
       "      <td>2019-03-24 22:20:00</td>\n",
       "      <td>170</td>\n",
       "      <td>0 days 02:50:00</td>\n",
       "      <td>2019-03-25 01:10:00</td>\n",
       "      <td>0.195297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Airline    Source Destination      Route  Total_Stops  Price  \\\n",
       "0  IndiGo  Banglore       Delhi  BLR → DEL          0.0   3897   \n",
       "\n",
       "    DepartureDateTime  Duration_min Duration_timedelta     ArrivalDateTime  \\\n",
       "0 2019-03-24 22:20:00           170    0 days 02:50:00 2019-03-25 01:10:00   \n",
       "\n",
       "   Freq_encoded_Airline  \n",
       "0              0.195297  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "14f38470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_encoder(df,col):\n",
    "    \"\"\"\n",
    "    This function encodes a categorical column based on the frequency of their occurence.\n",
    "    input:\n",
    "        df : Input DataFrame in which encoding has to be created \n",
    "        col : Column name which has to be encoded\n",
    "    return: \n",
    "          frequency encoded dictionary for columns\n",
    "    \"\"\"\n",
    "    freq_value = df.groupby(col).size()/len(df)\n",
    "    freq_dict = freq_value.to_dict()\n",
    "    df[\"Freq_encoded_\"+col] = df[col].replace(freq_dict)\n",
    "    return freq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "35797334",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'Airline'\n",
    "target_col = 'Price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9c51da08",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_value = df.groupby(col)[target_col].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4a96c432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Airline\n",
       "Air Asia                              5593.745283\n",
       "Air India                             9555.382891\n",
       "GoAir                                 5861.056701\n",
       "IndiGo                                5668.469897\n",
       "Jet Airways                          11599.021081\n",
       "Jet Airways Business                 58358.666667\n",
       "Multiple carriers                    10902.678094\n",
       "Multiple carriers Premium economy    11418.846154\n",
       "SpiceJet                              4335.841718\n",
       "Trujet                                4140.000000\n",
       "Vistara                               7801.761006\n",
       "Vistara Premium economy               8962.333333\n",
       "Name: Price, dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "be3a6f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dict = mean_value.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2f592f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Air Asia': 5593.745283018868,\n",
       " 'Air India': 9555.382890855457,\n",
       " 'GoAir': 5861.056701030928,\n",
       " 'IndiGo': 5668.469897209985,\n",
       " 'Jet Airways': 11599.02108108108,\n",
       " 'Jet Airways Business': 58358.666666666664,\n",
       " 'Multiple carriers': 10902.678093645485,\n",
       " 'Multiple carriers Premium economy': 11418.846153846154,\n",
       " 'SpiceJet': 4335.841717791411,\n",
       " 'Trujet': 4140.0,\n",
       " 'Vistara': 7801.761006289308,\n",
       " 'Vistara Premium economy': 8962.333333333334}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "68ff471b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Mean_encoded_\"+col] = df[col].replace(mean_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a98c58c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Price</th>\n",
       "      <th>DepartureDateTime</th>\n",
       "      <th>Duration_min</th>\n",
       "      <th>Duration_timedelta</th>\n",
       "      <th>ArrivalDateTime</th>\n",
       "      <th>Freq_encoded_Airline</th>\n",
       "      <th>Mean_encoded_Airline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>BLR → DEL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3897</td>\n",
       "      <td>2019-03-24 22:20:00</td>\n",
       "      <td>170</td>\n",
       "      <td>0 days 02:50:00</td>\n",
       "      <td>2019-03-25 01:10:00</td>\n",
       "      <td>0.195297</td>\n",
       "      <td>5668.469897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Airline    Source Destination      Route  Total_Stops  Price  \\\n",
       "0  IndiGo  Banglore       Delhi  BLR → DEL          0.0   3897   \n",
       "\n",
       "    DepartureDateTime  Duration_min Duration_timedelta     ArrivalDateTime  \\\n",
       "0 2019-03-24 22:20:00           170    0 days 02:50:00 2019-03-25 01:10:00   \n",
       "\n",
       "   Freq_encoded_Airline  Mean_encoded_Airline  \n",
       "0              0.195297           5668.469897  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4bd317ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_encoder(df,col,target_col):\n",
    "    \"\"\"\n",
    "    This function encodes a categorical column based on the frequency of their occurence.\n",
    "    input:\n",
    "        df : Input DataFrame in which encoding has to be created \n",
    "        col : Column name which has to be encoded\n",
    "    return: \n",
    "          Mean encoded dict for column\n",
    "    \"\"\"\n",
    "    mean_value = df.groupby(col)[target_col].mean()\n",
    "    mean_dict = mean_value.to_dict()\n",
    "    df[\"Mean_encoded_\"+col] = df[col].replace(mean_dict)\n",
    "    return mean_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "98f4e054",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Label encoder for function and later usages:\n",
    "\n",
    "## Applying Label Encoder to Categorical columns as Hit and Trail.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def label_encoder(df,col):\n",
    "    \"\"\"\n",
    "    This function encodes a categorical column based on the basis of their order label.\n",
    "    input:\n",
    "        df : Input DataFrame in which encoding has to be created \n",
    "        col : Column name which has to be encoded\n",
    "    return: \n",
    "          label encoded dict for column\n",
    "    \"\"\"\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df[col])\n",
    "    label_dict = dict(zip((le.classes_),le.transform(le.classes_)))\n",
    "    df[\"Label_encoded_\"+col] = df[col].replace(label_dict)\n",
    "    return label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "25dd20f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a function to handle categorical value\n",
    "def handle_categorical_values(df,target):\n",
    "    '''\n",
    "      This function handles categorical value and create a dataframe.\n",
    "      Input:\n",
    "        df : Dataframe which require categorical value treatment\n",
    "      returns :\n",
    "         Dataframe with all categorical value handled.\n",
    "    '''\n",
    "    encoded_dict = {}\n",
    "    # Getting all object columns\n",
    "    object_columns = df.select_dtypes(object).columns\n",
    "\n",
    "    ## generate frequency encoded categorical values\n",
    "    frequency_encoded_dict ={} \n",
    "    for col in object_columns:\n",
    "        freq_dict = frequency_encoder(df,col)\n",
    "        frequency_encoded_dict[col] = freq_dict\n",
    "\n",
    "    ## generate target mean encoded categorical values\n",
    "    mean_encoded_dict ={} \n",
    "    for col in object_columns:\n",
    "        mean_dict = mean_encoder(df,col,target)\n",
    "        mean_encoded_dict[col] = mean_dict\n",
    "\n",
    "    \n",
    "    ## generate label encoded categorical values\n",
    "    label_encoded_dict ={} \n",
    "    for col in object_columns:\n",
    "        label_dict = label_encoder(df,col)\n",
    "        label_encoded_dict[col] = label_dict\n",
    "    \n",
    "    encoded_dict[\"Frequency\"] = frequency_encoded_dict\n",
    "    encoded_dict[\"Mean\"] = mean_encoded_dict\n",
    "    encoded_dict[\"Label\"] = label_encoded_dict\n",
    "\n",
    "    return df, encoded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "69e79eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Airline', 'Source', 'Destination', 'Route'], dtype='object')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select_dtypes(object).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c0bd5f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Price'\n",
    "df, encoded_dict = handle_categorical_values(df,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "604c8a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Frequency': {'Airline': {'Air Asia': 0.030398623458560366,\n",
       "   'Air India': 0.16203039862345855,\n",
       "   'GoAir': 0.018545072172832425,\n",
       "   'IndiGo': 0.19529681674792085,\n",
       "   'Jet Airways': 0.35369467546123695,\n",
       "   'Jet Airways Business': 0.0005735589331803843,\n",
       "   'Multiple carriers': 0.1143294140139566,\n",
       "   'Multiple carriers Premium economy': 0.0012427110218908325,\n",
       "   'SpiceJet': 0.0779084217570022,\n",
       "   'Trujet': 9.559315553006405e-05,\n",
       "   'Vistara': 0.04559793518784055,\n",
       "   'Vistara Premium economy': 0.00028677946659019213},\n",
       "  'Source': {'Banglore': 0.20810629958894944,\n",
       "   'Chennai': 0.0364209922569544,\n",
       "   'Delhi': 0.41544785393365835,\n",
       "   'Kolkata': 0.2733964248159832,\n",
       "   'Mumbai': 0.06662842940445464},\n",
       "  'Destination': {'Banglore': 0.2733964248159832,\n",
       "   'Cochin': 0.41544785393365835,\n",
       "   'Delhi': 0.20810629958894944,\n",
       "   'Hyderabad': 0.06662842940445464,\n",
       "   'Kolkata': 0.0364209922569544},\n",
       "  'Route': {'BLR → AMD → DEL': 0.0017206767995411529,\n",
       "   'BLR → BBI → DEL': 0.00047796577765032023,\n",
       "   'BLR → BDQ → DEL': 0.0007647452442405124,\n",
       "   'BLR → BOM → AMD → DEL': 0.0003823726221202562,\n",
       "   'BLR → BOM → BHO → DEL': 0.0010515247108307045,\n",
       "   'BLR → BOM → DEL': 0.038428448523085745,\n",
       "   'BLR → BOM → IDR → DEL': 0.00047796577765032023,\n",
       "   'BLR → BOM → IDR → GWL → DEL': 0.0001911863110601281,\n",
       "   'BLR → BOM → IXC → DEL': 9.559315553006405e-05,\n",
       "   'BLR → BOM → JDH → DEL': 0.0005735589331803843,\n",
       "   'BLR → BOM → NAG → DEL': 0.0008603383997705764,\n",
       "   'BLR → BOM → UDR → DEL': 0.00028677946659019213,\n",
       "   'BLR → CCU → BBI → DEL': 0.00047796577765032023,\n",
       "   'BLR → CCU → BBI → HYD → DEL': 0.0001911863110601281,\n",
       "   'BLR → CCU → BBI → HYD → VGA → DEL': 9.559315553006405e-05,\n",
       "   'BLR → CCU → DEL': 0.0010515247108307045,\n",
       "   'BLR → CCU → GAU → DEL': 0.0010515247108307045,\n",
       "   'BLR → COK → DEL': 0.0014338973329509608,\n",
       "   'BLR → DEL': 0.14663990058311824,\n",
       "   'BLR → GAU → DEL': 0.00028677946659019213,\n",
       "   'BLR → GOI → DEL': 0.0006691520887104483,\n",
       "   'BLR → HBX → BOM → AMD → DEL': 9.559315553006405e-05,\n",
       "   'BLR → HBX → BOM → BHO → DEL': 9.559315553006405e-05,\n",
       "   'BLR → HBX → BOM → NAG → DEL': 9.559315553006405e-05,\n",
       "   'BLR → HYD → DEL': 0.0035369467546123696,\n",
       "   'BLR → HYD → VGA → DEL': 0.0009559315553006405,\n",
       "   'BLR → IDR → DEL': 0.00047796577765032023,\n",
       "   'BLR → LKO → DEL': 0.00028677946659019213,\n",
       "   'BLR → MAA → DEL': 0.0027722015103718574,\n",
       "   'BLR → NAG → DEL': 0.00028677946659019213,\n",
       "   'BLR → PNQ → DEL': 0.00047796577765032023,\n",
       "   'BLR → STV → DEL': 0.0001911863110601281,\n",
       "   'BLR → TRV → COK → DEL': 0.0001911863110601281,\n",
       "   'BLR → VGA → DEL': 0.0008603383997705764,\n",
       "   'BLR → VGA → HYD → DEL': 0.0003823726221202562,\n",
       "   'BLR → VGA → VTZ → DEL': 0.0001911863110601281,\n",
       "   'BOM → AMD → ISK → HYD': 0.0003823726221202562,\n",
       "   'BOM → BBI → HYD': 9.559315553006405e-05,\n",
       "   'BOM → BDQ → DEL → HYD': 0.0001911863110601281,\n",
       "   'BOM → BHO → DEL → HYD': 0.0006691520887104483,\n",
       "   'BOM → BLR → CCU → BBI → HYD': 9.559315553006405e-05,\n",
       "   'BOM → BLR → HYD': 0.00028677946659019213,\n",
       "   'BOM → CCU → HYD': 9.559315553006405e-05,\n",
       "   'BOM → COK → MAA → HYD': 9.559315553006405e-05,\n",
       "   'BOM → DED → DEL → HYD': 9.559315553006405e-05,\n",
       "   'BOM → DEL → HYD': 0.0031545741324921135,\n",
       "   'BOM → GOI → HYD': 9.559315553006405e-05,\n",
       "   'BOM → GOI → PNQ → HYD': 0.0005735589331803843,\n",
       "   'BOM → HYD': 0.05936334958416977,\n",
       "   'BOM → IDR → DEL → HYD': 0.0001911863110601281,\n",
       "   'BOM → JAI → DEL → HYD': 9.559315553006405e-05,\n",
       "   'BOM → JDH → DEL → HYD': 0.00028677946659019213,\n",
       "   'BOM → JDH → JAI → DEL → HYD': 9.559315553006405e-05,\n",
       "   'BOM → JLR → HYD': 9.559315553006405e-05,\n",
       "   'BOM → MAA → HYD': 0.00028677946659019213,\n",
       "   'BOM → NDC → HYD': 9.559315553006405e-05,\n",
       "   'BOM → RPR → VTZ → HYD': 9.559315553006405e-05,\n",
       "   'BOM → UDR → DEL → HYD': 9.559315553006405e-05,\n",
       "   'BOM → VNS → DEL → HYD': 9.559315553006405e-05,\n",
       "   'CCU → AMD → BLR': 0.0010515247108307045,\n",
       "   'CCU → BBI → BLR': 0.0047796577765032025,\n",
       "   'CCU → BBI → BOM → BLR': 0.00401491253226269,\n",
       "   'CCU → BBI → HYD → BLR': 0.0008603383997705764,\n",
       "   'CCU → BBI → IXR → DEL → BLR': 0.0001911863110601281,\n",
       "   'CCU → BLR': 0.06920944460376637,\n",
       "   'CCU → BOM → AMD → BLR': 0.0008603383997705764,\n",
       "   'CCU → BOM → BLR': 0.0935856992639327,\n",
       "   'CCU → BOM → COK → BLR': 0.0028677946659019216,\n",
       "   'CCU → BOM → GOI → BLR': 0.0012427110218908325,\n",
       "   'CCU → BOM → HBX → BLR': 0.0005735589331803843,\n",
       "   'CCU → BOM → PNQ → BLR': 0.0003823726221202562,\n",
       "   'CCU → BOM → TRV → BLR': 0.0001911863110601281,\n",
       "   'CCU → DEL → AMD → BLR': 0.002007456266131345,\n",
       "   'CCU → DEL → BLR': 0.05401013287448619,\n",
       "   'CCU → DEL → COK → BLR': 0.0027722015103718574,\n",
       "   'CCU → DEL → COK → TRV → BLR': 0.0003823726221202562,\n",
       "   'CCU → DEL → VGA → BLR': 0.0003823726221202562,\n",
       "   'CCU → GAU → BLR': 0.003919319376732626,\n",
       "   'CCU → GAU → DEL → BLR': 0.003632539910142434,\n",
       "   'CCU → GAU → IMF → DEL → BLR': 0.00047796577765032023,\n",
       "   'CCU → HYD → BLR': 0.005066437243093394,\n",
       "   'CCU → IXA → BLR': 9.559315553006405e-05,\n",
       "   'CCU → IXB → BLR': 0.001911863110601281,\n",
       "   'CCU → IXB → DEL → BLR': 9.559315553006405e-05,\n",
       "   'CCU → IXR → BBI → BLR': 0.0005735589331803843,\n",
       "   'CCU → IXR → DEL → BLR': 0.0043972851543829464,\n",
       "   'CCU → IXZ → MAA → BLR': 9.559315553006405e-05,\n",
       "   'CCU → JAI → BOM → BLR': 0.0012427110218908325,\n",
       "   'CCU → JAI → DEL → BLR': 0.0005735589331803843,\n",
       "   'CCU → KNU → BLR': 0.0009559315553006405,\n",
       "   'CCU → MAA → BLR': 0.006213555109454163,\n",
       "   'CCU → NAG → BLR': 0.0008603383997705764,\n",
       "   'CCU → PAT → BLR': 0.0009559315553006405,\n",
       "   'CCU → PNQ → BLR': 0.001816269955071217,\n",
       "   'CCU → RPR → HYD → BLR': 9.559315553006405e-05,\n",
       "   'CCU → VNS → DEL → BLR': 0.0009559315553006405,\n",
       "   'CCU → VTZ → BLR': 9.559315553006405e-05,\n",
       "   'DEL → AMD → BOM → COK': 0.013765414396329223,\n",
       "   'DEL → AMD → COK': 0.0023898288882516013,\n",
       "   'DEL → ATQ → BOM → COK': 0.003823726221202562,\n",
       "   'DEL → BBI → COK': 0.00047796577765032023,\n",
       "   'DEL → BDQ → BOM → COK': 0.0025810151993117293,\n",
       "   'DEL → BHO → BOM → COK': 0.004588471465443074,\n",
       "   'DEL → BLR → COK': 0.02217761208297486,\n",
       "   'DEL → BOM → COK': 0.22712933753943218,\n",
       "   'DEL → CCU → BOM → COK': 0.004206098843322818,\n",
       "   'DEL → COK': 0.020361342127903644,\n",
       "   'DEL → DED → BOM → COK': 0.0001911863110601281,\n",
       "   'DEL → GOI → BOM → COK': 0.004206098843322818,\n",
       "   'DEL → GWL → IDR → BOM → COK': 0.0007647452442405124,\n",
       "   'DEL → HYD → BOM → COK': 0.004301691998852882,\n",
       "   'DEL → HYD → COK': 0.03116336870280088,\n",
       "   'DEL → HYD → MAA → COK': 0.007934231908995316,\n",
       "   'DEL → IDR → BOM → COK': 0.008603383997705764,\n",
       "   'DEL → IXC → BOM → COK': 0.0010515247108307045,\n",
       "   'DEL → IXU → BOM → COK': 0.0011471178663607685,\n",
       "   'DEL → JAI → BOM → COK': 0.01749354746200172,\n",
       "   'DEL → JDH → BOM → COK': 0.0035369467546123696,\n",
       "   'DEL → LKO → BOM → COK': 0.003919319376732626,\n",
       "   'DEL → LKO → COK': 0.0016250836440110889,\n",
       "   'DEL → MAA → BOM → COK': 0.0010515247108307045,\n",
       "   'DEL → MAA → COK': 0.013956600707389352,\n",
       "   'DEL → NAG → BOM → COK': 0.004206098843322818,\n",
       "   'DEL → PNQ → COK': 0.00401491253226269,\n",
       "   'DEL → RPR → NAG → BOM → COK': 0.0014338973329509608,\n",
       "   'DEL → TRV → COK': 0.0015294904884810248,\n",
       "   'DEL → UDR → BOM → COK': 0.0017206767995411529,\n",
       "   'MAA → CCU': 0.0364209922569544}},\n",
       " 'Mean': {'Airline': {'Air Asia': 5593.745283018868,\n",
       "   'Air India': 9555.382890855457,\n",
       "   'GoAir': 5861.056701030928,\n",
       "   'IndiGo': 5668.469897209985,\n",
       "   'Jet Airways': 11599.02108108108,\n",
       "   'Jet Airways Business': 58358.666666666664,\n",
       "   'Multiple carriers': 10902.678093645485,\n",
       "   'Multiple carriers Premium economy': 11418.846153846154,\n",
       "   'SpiceJet': 4335.841717791411,\n",
       "   'Trujet': 4140.0,\n",
       "   'Vistara': 7801.761006289308,\n",
       "   'Vistara Premium economy': 8962.333333333334},\n",
       "  'Source': {'Banglore': 8024.689940284796,\n",
       "   'Chennai': 4789.892388451443,\n",
       "   'Delhi': 10460.914634146342,\n",
       "   'Kolkata': 9143.083566433566,\n",
       "   'Mumbai': 5059.708751793401},\n",
       "  'Destination': {'Banglore': 9143.083566433566,\n",
       "   'Cochin': 10460.914634146342,\n",
       "   'Delhi': 8024.689940284796,\n",
       "   'Hyderabad': 5059.708751793401,\n",
       "   'Kolkata': 4789.892388451443},\n",
       "  'Route': {'BLR → AMD → DEL': 11134.166666666666,\n",
       "   'BLR → BBI → DEL': 11486.0,\n",
       "   'BLR → BDQ → DEL': 11550.5,\n",
       "   'BLR → BOM → AMD → DEL': 14155.75,\n",
       "   'BLR → BOM → BHO → DEL': 17211.545454545456,\n",
       "   'BLR → BOM → DEL': 15723.174129353234,\n",
       "   'BLR → BOM → IDR → DEL': 15360.6,\n",
       "   'BLR → BOM → IDR → GWL → DEL': 13387.0,\n",
       "   'BLR → BOM → IXC → DEL': 13303.0,\n",
       "   'BLR → BOM → JDH → DEL': 14845.833333333334,\n",
       "   'BLR → BOM → NAG → DEL': 14685.333333333334,\n",
       "   'BLR → BOM → UDR → DEL': 11937.666666666666,\n",
       "   'BLR → CCU → BBI → DEL': 9155.0,\n",
       "   'BLR → CCU → BBI → HYD → DEL': 12713.5,\n",
       "   'BLR → CCU → BBI → HYD → VGA → DEL': 17686.0,\n",
       "   'BLR → CCU → DEL': 12260.272727272728,\n",
       "   'BLR → CCU → GAU → DEL': 11810.0,\n",
       "   'BLR → COK → DEL': 9139.133333333333,\n",
       "   'BLR → DEL': 5551.593220338983,\n",
       "   'BLR → GAU → DEL': 12508.333333333334,\n",
       "   'BLR → GOI → DEL': 8759.857142857143,\n",
       "   'BLR → HBX → BOM → AMD → DEL': 10573.0,\n",
       "   'BLR → HBX → BOM → BHO → DEL': 14195.0,\n",
       "   'BLR → HBX → BOM → NAG → DEL': 12358.0,\n",
       "   'BLR → HYD → DEL': 6473.027027027027,\n",
       "   'BLR → HYD → VGA → DEL': 10770.7,\n",
       "   'BLR → IDR → DEL': 7610.4,\n",
       "   'BLR → LKO → DEL': 7334.333333333333,\n",
       "   'BLR → MAA → DEL': 12071.965517241379,\n",
       "   'BLR → NAG → DEL': 11313.0,\n",
       "   'BLR → PNQ → DEL': 11888.4,\n",
       "   'BLR → STV → DEL': 5746.0,\n",
       "   'BLR → TRV → COK → DEL': 11838.0,\n",
       "   'BLR → VGA → DEL': 9002.222222222223,\n",
       "   'BLR → VGA → HYD → DEL': 9598.75,\n",
       "   'BLR → VGA → VTZ → DEL': 15361.0,\n",
       "   'BOM → AMD → ISK → HYD': 11762.0,\n",
       "   'BOM → BBI → HYD': 14408.0,\n",
       "   'BOM → BDQ → DEL → HYD': 22792.5,\n",
       "   'BOM → BHO → DEL → HYD': 13161.57142857143,\n",
       "   'BOM → BLR → CCU → BBI → HYD': 14260.0,\n",
       "   'BOM → BLR → HYD': 9045.0,\n",
       "   'BOM → CCU → HYD': 16666.0,\n",
       "   'BOM → COK → MAA → HYD': 9678.0,\n",
       "   'BOM → DED → DEL → HYD': 24115.0,\n",
       "   'BOM → DEL → HYD': 13379.515151515152,\n",
       "   'BOM → GOI → HYD': 7681.0,\n",
       "   'BOM → GOI → PNQ → HYD': 17082.0,\n",
       "   'BOM → HYD': 3932.8099838969406,\n",
       "   'BOM → IDR → DEL → HYD': 17049.0,\n",
       "   'BOM → JAI → DEL → HYD': 17926.0,\n",
       "   'BOM → JDH → DEL → HYD': 23867.0,\n",
       "   'BOM → JDH → JAI → DEL → HYD': 18293.0,\n",
       "   'BOM → JLR → HYD': 13552.0,\n",
       "   'BOM → MAA → HYD': 8598.333333333334,\n",
       "   'BOM → NDC → HYD': 4140.0,\n",
       "   'BOM → RPR → VTZ → HYD': 9736.0,\n",
       "   'BOM → UDR → DEL → HYD': 22950.0,\n",
       "   'BOM → VNS → DEL → HYD': 23528.0,\n",
       "   'CCU → AMD → BLR': 8382.636363636364,\n",
       "   'CCU → BBI → BLR': 6060.6,\n",
       "   'CCU → BBI → BOM → BLR': 10457.404761904761,\n",
       "   'CCU → BBI → HYD → BLR': 5790.333333333333,\n",
       "   'CCU → BBI → IXR → DEL → BLR': 12606.0,\n",
       "   'CCU → BLR': 4556.055248618784,\n",
       "   'CCU → BOM → AMD → BLR': 14424.444444444445,\n",
       "   'CCU → BOM → BLR': 11487.788559754852,\n",
       "   'CCU → BOM → COK → BLR': 12864.833333333334,\n",
       "   'CCU → BOM → GOI → BLR': 11809.76923076923,\n",
       "   'CCU → BOM → HBX → BLR': 10037.166666666666,\n",
       "   'CCU → BOM → PNQ → BLR': 10118.0,\n",
       "   'CCU → BOM → TRV → BLR': 12403.0,\n",
       "   'CCU → DEL → AMD → BLR': 13719.095238095239,\n",
       "   'CCU → DEL → BLR': 10763.258407079646,\n",
       "   'CCU → DEL → COK → BLR': 13486.241379310344,\n",
       "   'CCU → DEL → COK → TRV → BLR': 12941.25,\n",
       "   'CCU → DEL → VGA → BLR': 12533.25,\n",
       "   'CCU → GAU → BLR': 7612.682926829269,\n",
       "   'CCU → GAU → DEL → BLR': 13892.052631578947,\n",
       "   'CCU → GAU → IMF → DEL → BLR': 13537.4,\n",
       "   'CCU → HYD → BLR': 4910.018867924528,\n",
       "   'CCU → IXA → BLR': 9413.0,\n",
       "   'CCU → IXB → BLR': 9275.25,\n",
       "   'CCU → IXB → DEL → BLR': 15292.0,\n",
       "   'CCU → IXR → BBI → BLR': 7369.166666666667,\n",
       "   'CCU → IXR → DEL → BLR': 10969.065217391304,\n",
       "   'CCU → IXZ → MAA → BLR': 11522.0,\n",
       "   'CCU → JAI → BOM → BLR': 10874.692307692309,\n",
       "   'CCU → JAI → DEL → BLR': 12053.0,\n",
       "   'CCU → KNU → BLR': 8623.4,\n",
       "   'CCU → MAA → BLR': 5240.876923076923,\n",
       "   'CCU → NAG → BLR': 6279.333333333333,\n",
       "   'CCU → PAT → BLR': 10821.3,\n",
       "   'CCU → PNQ → BLR': 6703.421052631579,\n",
       "   'CCU → RPR → HYD → BLR': 6103.0,\n",
       "   'CCU → VNS → DEL → BLR': 15164.5,\n",
       "   'CCU → VTZ → BLR': 6301.0,\n",
       "   'DEL → AMD → BOM → COK': 12630.173611111111,\n",
       "   'DEL → AMD → COK': 5606.2,\n",
       "   'DEL → ATQ → BOM → COK': 16699.675,\n",
       "   'DEL → BBI → COK': 11062.6,\n",
       "   'DEL → BDQ → BOM → COK': 12339.444444444445,\n",
       "   'DEL → BHO → BOM → COK': 14120.645833333334,\n",
       "   'DEL → BLR → COK': 7559.612068965517,\n",
       "   'DEL → BOM → COK': 10954.205808080807,\n",
       "   'DEL → CCU → BOM → COK': 13962.431818181818,\n",
       "   'DEL → COK': 6315.816901408451,\n",
       "   'DEL → DED → BOM → COK': 19539.5,\n",
       "   'DEL → GOI → BOM → COK': 11941.818181818182,\n",
       "   'DEL → GWL → IDR → BOM → COK': 17292.75,\n",
       "   'DEL → HYD → BOM → COK': 11724.577777777778,\n",
       "   'DEL → HYD → COK': 7299.331288343558,\n",
       "   'DEL → HYD → MAA → COK': 9133.469879518072,\n",
       "   'DEL → IDR → BOM → COK': 14038.122222222222,\n",
       "   'DEL → IXC → BOM → COK': 12514.545454545454,\n",
       "   'DEL → IXU → BOM → COK': 19381.333333333332,\n",
       "   'DEL → JAI → BOM → COK': 12210.196721311475,\n",
       "   'DEL → JDH → BOM → COK': 16163.135135135135,\n",
       "   'DEL → LKO → BOM → COK': 13277.19512195122,\n",
       "   'DEL → LKO → COK': 7166.176470588235,\n",
       "   'DEL → MAA → BOM → COK': 9161.636363636364,\n",
       "   'DEL → MAA → COK': 7312.431506849315,\n",
       "   'DEL → NAG → BOM → COK': 12171.227272727272,\n",
       "   'DEL → PNQ → COK': 6602.071428571428,\n",
       "   'DEL → RPR → NAG → BOM → COK': 11021.533333333333,\n",
       "   'DEL → TRV → COK': 7835.625,\n",
       "   'DEL → UDR → BOM → COK': 13859.277777777777,\n",
       "   'MAA → CCU': 4789.892388451443}},\n",
       " 'Label': {'Airline': {'Air Asia': 0,\n",
       "   'Air India': 1,\n",
       "   'GoAir': 2,\n",
       "   'IndiGo': 3,\n",
       "   'Jet Airways': 4,\n",
       "   'Jet Airways Business': 5,\n",
       "   'Multiple carriers': 6,\n",
       "   'Multiple carriers Premium economy': 7,\n",
       "   'SpiceJet': 8,\n",
       "   'Trujet': 9,\n",
       "   'Vistara': 10,\n",
       "   'Vistara Premium economy': 11},\n",
       "  'Source': {'Banglore': 0,\n",
       "   'Chennai': 1,\n",
       "   'Delhi': 2,\n",
       "   'Kolkata': 3,\n",
       "   'Mumbai': 4},\n",
       "  'Destination': {'Banglore': 0,\n",
       "   'Cochin': 1,\n",
       "   'Delhi': 2,\n",
       "   'Hyderabad': 3,\n",
       "   'Kolkata': 4},\n",
       "  'Route': {'BLR → AMD → DEL': 0,\n",
       "   'BLR → BBI → DEL': 1,\n",
       "   'BLR → BDQ → DEL': 2,\n",
       "   'BLR → BOM → AMD → DEL': 3,\n",
       "   'BLR → BOM → BHO → DEL': 4,\n",
       "   'BLR → BOM → DEL': 5,\n",
       "   'BLR → BOM → IDR → DEL': 6,\n",
       "   'BLR → BOM → IDR → GWL → DEL': 7,\n",
       "   'BLR → BOM → IXC → DEL': 8,\n",
       "   'BLR → BOM → JDH → DEL': 9,\n",
       "   'BLR → BOM → NAG → DEL': 10,\n",
       "   'BLR → BOM → UDR → DEL': 11,\n",
       "   'BLR → CCU → BBI → DEL': 12,\n",
       "   'BLR → CCU → BBI → HYD → DEL': 13,\n",
       "   'BLR → CCU → BBI → HYD → VGA → DEL': 14,\n",
       "   'BLR → CCU → DEL': 15,\n",
       "   'BLR → CCU → GAU → DEL': 16,\n",
       "   'BLR → COK → DEL': 17,\n",
       "   'BLR → DEL': 18,\n",
       "   'BLR → GAU → DEL': 19,\n",
       "   'BLR → GOI → DEL': 20,\n",
       "   'BLR → HBX → BOM → AMD → DEL': 21,\n",
       "   'BLR → HBX → BOM → BHO → DEL': 22,\n",
       "   'BLR → HBX → BOM → NAG → DEL': 23,\n",
       "   'BLR → HYD → DEL': 24,\n",
       "   'BLR → HYD → VGA → DEL': 25,\n",
       "   'BLR → IDR → DEL': 26,\n",
       "   'BLR → LKO → DEL': 27,\n",
       "   'BLR → MAA → DEL': 28,\n",
       "   'BLR → NAG → DEL': 29,\n",
       "   'BLR → PNQ → DEL': 30,\n",
       "   'BLR → STV → DEL': 31,\n",
       "   'BLR → TRV → COK → DEL': 32,\n",
       "   'BLR → VGA → DEL': 33,\n",
       "   'BLR → VGA → HYD → DEL': 34,\n",
       "   'BLR → VGA → VTZ → DEL': 35,\n",
       "   'BOM → AMD → ISK → HYD': 36,\n",
       "   'BOM → BBI → HYD': 37,\n",
       "   'BOM → BDQ → DEL → HYD': 38,\n",
       "   'BOM → BHO → DEL → HYD': 39,\n",
       "   'BOM → BLR → CCU → BBI → HYD': 40,\n",
       "   'BOM → BLR → HYD': 41,\n",
       "   'BOM → CCU → HYD': 42,\n",
       "   'BOM → COK → MAA → HYD': 43,\n",
       "   'BOM → DED → DEL → HYD': 44,\n",
       "   'BOM → DEL → HYD': 45,\n",
       "   'BOM → GOI → HYD': 46,\n",
       "   'BOM → GOI → PNQ → HYD': 47,\n",
       "   'BOM → HYD': 48,\n",
       "   'BOM → IDR → DEL → HYD': 49,\n",
       "   'BOM → JAI → DEL → HYD': 50,\n",
       "   'BOM → JDH → DEL → HYD': 51,\n",
       "   'BOM → JDH → JAI → DEL → HYD': 52,\n",
       "   'BOM → JLR → HYD': 53,\n",
       "   'BOM → MAA → HYD': 54,\n",
       "   'BOM → NDC → HYD': 55,\n",
       "   'BOM → RPR → VTZ → HYD': 56,\n",
       "   'BOM → UDR → DEL → HYD': 57,\n",
       "   'BOM → VNS → DEL → HYD': 58,\n",
       "   'CCU → AMD → BLR': 59,\n",
       "   'CCU → BBI → BLR': 60,\n",
       "   'CCU → BBI → BOM → BLR': 61,\n",
       "   'CCU → BBI → HYD → BLR': 62,\n",
       "   'CCU → BBI → IXR → DEL → BLR': 63,\n",
       "   'CCU → BLR': 64,\n",
       "   'CCU → BOM → AMD → BLR': 65,\n",
       "   'CCU → BOM → BLR': 66,\n",
       "   'CCU → BOM → COK → BLR': 67,\n",
       "   'CCU → BOM → GOI → BLR': 68,\n",
       "   'CCU → BOM → HBX → BLR': 69,\n",
       "   'CCU → BOM → PNQ → BLR': 70,\n",
       "   'CCU → BOM → TRV → BLR': 71,\n",
       "   'CCU → DEL → AMD → BLR': 72,\n",
       "   'CCU → DEL → BLR': 73,\n",
       "   'CCU → DEL → COK → BLR': 74,\n",
       "   'CCU → DEL → COK → TRV → BLR': 75,\n",
       "   'CCU → DEL → VGA → BLR': 76,\n",
       "   'CCU → GAU → BLR': 77,\n",
       "   'CCU → GAU → DEL → BLR': 78,\n",
       "   'CCU → GAU → IMF → DEL → BLR': 79,\n",
       "   'CCU → HYD → BLR': 80,\n",
       "   'CCU → IXA → BLR': 81,\n",
       "   'CCU → IXB → BLR': 82,\n",
       "   'CCU → IXB → DEL → BLR': 83,\n",
       "   'CCU → IXR → BBI → BLR': 84,\n",
       "   'CCU → IXR → DEL → BLR': 85,\n",
       "   'CCU → IXZ → MAA → BLR': 86,\n",
       "   'CCU → JAI → BOM → BLR': 87,\n",
       "   'CCU → JAI → DEL → BLR': 88,\n",
       "   'CCU → KNU → BLR': 89,\n",
       "   'CCU → MAA → BLR': 90,\n",
       "   'CCU → NAG → BLR': 91,\n",
       "   'CCU → PAT → BLR': 92,\n",
       "   'CCU → PNQ → BLR': 93,\n",
       "   'CCU → RPR → HYD → BLR': 94,\n",
       "   'CCU → VNS → DEL → BLR': 95,\n",
       "   'CCU → VTZ → BLR': 96,\n",
       "   'DEL → AMD → BOM → COK': 97,\n",
       "   'DEL → AMD → COK': 98,\n",
       "   'DEL → ATQ → BOM → COK': 99,\n",
       "   'DEL → BBI → COK': 100,\n",
       "   'DEL → BDQ → BOM → COK': 101,\n",
       "   'DEL → BHO → BOM → COK': 102,\n",
       "   'DEL → BLR → COK': 103,\n",
       "   'DEL → BOM → COK': 104,\n",
       "   'DEL → CCU → BOM → COK': 105,\n",
       "   'DEL → COK': 106,\n",
       "   'DEL → DED → BOM → COK': 107,\n",
       "   'DEL → GOI → BOM → COK': 108,\n",
       "   'DEL → GWL → IDR → BOM → COK': 109,\n",
       "   'DEL → HYD → BOM → COK': 110,\n",
       "   'DEL → HYD → COK': 111,\n",
       "   'DEL → HYD → MAA → COK': 112,\n",
       "   'DEL → IDR → BOM → COK': 113,\n",
       "   'DEL → IXC → BOM → COK': 114,\n",
       "   'DEL → IXU → BOM → COK': 115,\n",
       "   'DEL → JAI → BOM → COK': 116,\n",
       "   'DEL → JDH → BOM → COK': 117,\n",
       "   'DEL → LKO → BOM → COK': 118,\n",
       "   'DEL → LKO → COK': 119,\n",
       "   'DEL → MAA → BOM → COK': 120,\n",
       "   'DEL → MAA → COK': 121,\n",
       "   'DEL → NAG → BOM → COK': 122,\n",
       "   'DEL → PNQ → COK': 123,\n",
       "   'DEL → RPR → NAG → BOM → COK': 124,\n",
       "   'DEL → TRV → COK': 125,\n",
       "   'DEL → UDR → BOM → COK': 126,\n",
       "   'MAA → CCU': 127,\n",
       "   nan: 128}}}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "de4958c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Price</th>\n",
       "      <th>DepartureDateTime</th>\n",
       "      <th>Duration_min</th>\n",
       "      <th>Duration_timedelta</th>\n",
       "      <th>ArrivalDateTime</th>\n",
       "      <th>...</th>\n",
       "      <th>Freq_encoded_Source</th>\n",
       "      <th>Freq_encoded_Destination</th>\n",
       "      <th>Freq_encoded_Route</th>\n",
       "      <th>Mean_encoded_Source</th>\n",
       "      <th>Mean_encoded_Destination</th>\n",
       "      <th>Mean_encoded_Route</th>\n",
       "      <th>Label_encoded_Airline</th>\n",
       "      <th>Label_encoded_Source</th>\n",
       "      <th>Label_encoded_Destination</th>\n",
       "      <th>Label_encoded_Route</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>BLR → DEL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3897</td>\n",
       "      <td>2019-03-24 22:20:00</td>\n",
       "      <td>170</td>\n",
       "      <td>0 days 02:50:00</td>\n",
       "      <td>2019-03-25 01:10:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208106</td>\n",
       "      <td>0.208106</td>\n",
       "      <td>0.146640</td>\n",
       "      <td>8024.689940</td>\n",
       "      <td>8024.689940</td>\n",
       "      <td>5551.593220</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air India</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU → IXR → BBI → BLR</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7662</td>\n",
       "      <td>2019-05-01 05:50:00</td>\n",
       "      <td>445</td>\n",
       "      <td>0 days 07:25:00</td>\n",
       "      <td>2019-05-01 13:15:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273396</td>\n",
       "      <td>0.273396</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>9143.083566</td>\n",
       "      <td>9143.083566</td>\n",
       "      <td>7369.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Airline    Source Destination                  Route  Total_Stops  Price  \\\n",
       "0     IndiGo  Banglore       Delhi              BLR → DEL          0.0   3897   \n",
       "1  Air India   Kolkata    Banglore  CCU → IXR → BBI → BLR          2.0   7662   \n",
       "\n",
       "    DepartureDateTime  Duration_min Duration_timedelta     ArrivalDateTime  \\\n",
       "0 2019-03-24 22:20:00           170    0 days 02:50:00 2019-03-25 01:10:00   \n",
       "1 2019-05-01 05:50:00           445    0 days 07:25:00 2019-05-01 13:15:00   \n",
       "\n",
       "   ...  Freq_encoded_Source  Freq_encoded_Destination  Freq_encoded_Route  \\\n",
       "0  ...             0.208106                  0.208106            0.146640   \n",
       "1  ...             0.273396                  0.273396            0.000574   \n",
       "\n",
       "   Mean_encoded_Source  Mean_encoded_Destination  Mean_encoded_Route  \\\n",
       "0          8024.689940               8024.689940         5551.593220   \n",
       "1          9143.083566               9143.083566         7369.166667   \n",
       "\n",
       "   Label_encoded_Airline  Label_encoded_Source  Label_encoded_Destination  \\\n",
       "0                      3                     0                          2   \n",
       "1                      1                     3                          0   \n",
       "\n",
       "   Label_encoded_Route  \n",
       "0                 18.0  \n",
       "1                 84.0  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c9cfab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['Airline', 'Source', 'Destination', 'Route']\n",
    "df.drop(columns=categorical_cols,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d9fb97",
   "metadata": {},
   "source": [
    "#### Action on categorical Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "35154dc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Destination'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Destination'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 95\u001b[0m\n\u001b[0;32m     92\u001b[0m     df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39mcategorical_cols,inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df, encoded_dict\n\u001b[1;32m---> 95\u001b[0m df, encoded_dict \u001b[38;5;241m=\u001b[39m airline_handle_categorical_data(df,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrice\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[90], line 89\u001b[0m, in \u001b[0;36mairline_handle_categorical_data\u001b[1;34m(df, target)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mairline_handle_categorical_data\u001b[39m(df,target):\n\u001b[1;32m---> 89\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDestination\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDestination\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNew Delhi\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDelhi\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m     90\u001b[0m     df, encoded_dict \u001b[38;5;241m=\u001b[39m handle_categorical_values(df,target)\n\u001b[0;32m     91\u001b[0m     categorical_cols \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mselect_dtypes(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39mcolumns\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Destination'"
     ]
    }
   ],
   "source": [
    "def frequency_encoder(df,col):\n",
    "    \"\"\"\n",
    "    This function encodes a categorical column based on the frequency of their occurence.\n",
    "    input:\n",
    "        df : Input DataFrame in which encoding has to be created \n",
    "        col : Column name which has to be encoded\n",
    "    return: \n",
    "          frequency encoded dictionary for columns\n",
    "    \"\"\"\n",
    "    freq_value = df.groupby(col).size()/len(df)\n",
    "    freq_dict = freq_value.to_dict()\n",
    "    df[\"Freq_encoded_\"+col] = df[col].replace(freq_dict)\n",
    "    return freq_dict\n",
    "\n",
    "\n",
    "def mean_encoder(df,col,target_col):\n",
    "    \"\"\"\n",
    "    This function encodes a categorical column based on the frequency of their occurence.\n",
    "    input:\n",
    "        df : Input DataFrame in which encoding has to be created \n",
    "        col : Column name which has to be encoded\n",
    "    return: \n",
    "          Mean encoded dict for column\n",
    "    \"\"\"\n",
    "    mean_value = df.groupby(col)[target_col].mean()\n",
    "    mean_dict = mean_value.to_dict()\n",
    "    df[\"Mean_encoded_\"+col] = df[col].replace(mean_dict)\n",
    "    return mean_dict\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def label_encoder(df,col):\n",
    "    \"\"\"\n",
    "    This function encodes a categorical column based on the basis of their order label.\n",
    "    input:\n",
    "        df : Input DataFrame in which encoding has to be created \n",
    "        col : Column name which has to be encoded\n",
    "    return: \n",
    "          label encoded dict for column\n",
    "    \"\"\"\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df[col])\n",
    "    label_dict = dict(zip((le.classes_),le.transform(le.classes_)))\n",
    "    df[\"Label_encoded_\"+col] = df[col].replace(label_dict)\n",
    "    return label_dict\n",
    "\n",
    "\n",
    "## Create a function to handle categorical value\n",
    "def handle_categorical_values(df,target):\n",
    "    '''\n",
    "      This function handles categorical value and create a dataframe.\n",
    "      Input:\n",
    "        df : Dataframe which require categorical value treatment\n",
    "      returns :\n",
    "         Dataframe with all categorical value handled.\n",
    "    '''\n",
    "    encoded_dict = {}\n",
    "    # Getting all object columns\n",
    "    object_columns = df.select_dtypes(object).columns\n",
    "\n",
    "    ## generate frequency encoded categorical values\n",
    "    frequency_encoded_dict ={} \n",
    "    for col in object_columns:\n",
    "        freq_dict = frequency_encoder(df,col)\n",
    "        frequency_encoded_dict[col] = freq_dict\n",
    "\n",
    "    ## generate target mean encoded categorical values\n",
    "    mean_encoded_dict ={} \n",
    "    for col in object_columns:\n",
    "        mean_dict = mean_encoder(df,col,target)\n",
    "        mean_encoded_dict[col] = mean_dict\n",
    "\n",
    "    \n",
    "    ## generate label encoded categorical values\n",
    "    label_encoded_dict ={} \n",
    "    for col in object_columns:\n",
    "        label_dict = label_encoder(df,col)\n",
    "        label_encoded_dict[col] = label_dict\n",
    "    \n",
    "    encoded_dict[\"Frequency\"] = frequency_encoded_dict\n",
    "    encoded_dict[\"Mean\"] = mean_encoded_dict\n",
    "    encoded_dict[\"Label\"] = label_encoded_dict\n",
    "\n",
    "    return df, encoded_dict\n",
    "\n",
    "\n",
    "def airline_handle_categorical_data(df,target):\n",
    "    df['Destination'] = df['Destination'].replace({'New Delhi':'Delhi'})\n",
    "    df, encoded_dict = handle_categorical_values(df,target)\n",
    "    categorical_cols = df.select_dtypes(object).columns\n",
    "    df.drop(columns=categorical_cols,inplace=True)\n",
    "    return df, encoded_dict\n",
    "\n",
    "df, encoded_dict = airline_handle_categorical_data(df,'Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285aa114",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8e96e437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Price</th>\n",
       "      <th>DepartureDateTime</th>\n",
       "      <th>Duration_min</th>\n",
       "      <th>Duration_timedelta</th>\n",
       "      <th>ArrivalDateTime</th>\n",
       "      <th>Freq_encoded_Airline</th>\n",
       "      <th>Mean_encoded_Airline</th>\n",
       "      <th>Freq_encoded_Source</th>\n",
       "      <th>Freq_encoded_Destination</th>\n",
       "      <th>Freq_encoded_Route</th>\n",
       "      <th>Mean_encoded_Source</th>\n",
       "      <th>Mean_encoded_Destination</th>\n",
       "      <th>Mean_encoded_Route</th>\n",
       "      <th>Label_encoded_Airline</th>\n",
       "      <th>Label_encoded_Source</th>\n",
       "      <th>Label_encoded_Destination</th>\n",
       "      <th>Label_encoded_Route</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total_Stops</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.601978</td>\n",
       "      <td>0.032399</td>\n",
       "      <td>0.727930</td>\n",
       "      <td>0.727930</td>\n",
       "      <td>0.039369</td>\n",
       "      <td>0.211636</td>\n",
       "      <td>0.421194</td>\n",
       "      <td>0.571425</td>\n",
       "      <td>0.571425</td>\n",
       "      <td>-0.205132</td>\n",
       "      <td>0.559061</td>\n",
       "      <td>0.559061</td>\n",
       "      <td>0.806659</td>\n",
       "      <td>-0.194563</td>\n",
       "      <td>0.193899</td>\n",
       "      <td>-0.422555</td>\n",
       "      <td>0.441153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <td>0.601978</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.149351</td>\n",
       "      <td>0.501597</td>\n",
       "      <td>0.501597</td>\n",
       "      <td>-0.144545</td>\n",
       "      <td>0.371569</td>\n",
       "      <td>0.638622</td>\n",
       "      <td>0.350856</td>\n",
       "      <td>0.350856</td>\n",
       "      <td>0.039251</td>\n",
       "      <td>0.359852</td>\n",
       "      <td>0.359852</td>\n",
       "      <td>0.746261</td>\n",
       "      <td>-0.036549</td>\n",
       "      <td>0.013596</td>\n",
       "      <td>-0.260673</td>\n",
       "      <td>0.154164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DepartureDateTime</th>\n",
       "      <td>0.032399</td>\n",
       "      <td>-0.149351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003145</td>\n",
       "      <td>-0.003145</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.029146</td>\n",
       "      <td>0.029206</td>\n",
       "      <td>0.160360</td>\n",
       "      <td>0.160360</td>\n",
       "      <td>0.105370</td>\n",
       "      <td>0.146240</td>\n",
       "      <td>0.146240</td>\n",
       "      <td>-0.061108</td>\n",
       "      <td>0.031828</td>\n",
       "      <td>0.178190</td>\n",
       "      <td>-0.146161</td>\n",
       "      <td>0.249640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Duration_min</th>\n",
       "      <td>0.727930</td>\n",
       "      <td>0.501597</td>\n",
       "      <td>-0.003145</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006431</td>\n",
       "      <td>0.289261</td>\n",
       "      <td>0.433855</td>\n",
       "      <td>0.400089</td>\n",
       "      <td>0.400089</td>\n",
       "      <td>-0.110685</td>\n",
       "      <td>0.414909</td>\n",
       "      <td>0.414909</td>\n",
       "      <td>0.671820</td>\n",
       "      <td>-0.153788</td>\n",
       "      <td>0.162560</td>\n",
       "      <td>-0.383666</td>\n",
       "      <td>0.273175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Duration_timedelta</th>\n",
       "      <td>0.727930</td>\n",
       "      <td>0.501597</td>\n",
       "      <td>-0.003145</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006431</td>\n",
       "      <td>0.289261</td>\n",
       "      <td>0.433855</td>\n",
       "      <td>0.400089</td>\n",
       "      <td>0.400089</td>\n",
       "      <td>-0.110685</td>\n",
       "      <td>0.414909</td>\n",
       "      <td>0.414909</td>\n",
       "      <td>0.671820</td>\n",
       "      <td>-0.153788</td>\n",
       "      <td>0.162560</td>\n",
       "      <td>-0.383666</td>\n",
       "      <td>0.273175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ArrivalDateTime</th>\n",
       "      <td>0.039369</td>\n",
       "      <td>-0.144545</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.006431</td>\n",
       "      <td>0.006431</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.031915</td>\n",
       "      <td>0.033360</td>\n",
       "      <td>0.164188</td>\n",
       "      <td>0.164188</td>\n",
       "      <td>0.104308</td>\n",
       "      <td>0.150211</td>\n",
       "      <td>0.150211</td>\n",
       "      <td>-0.054674</td>\n",
       "      <td>0.030355</td>\n",
       "      <td>0.179744</td>\n",
       "      <td>-0.149833</td>\n",
       "      <td>0.252252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_encoded_Airline</th>\n",
       "      <td>0.211636</td>\n",
       "      <td>0.371569</td>\n",
       "      <td>0.029146</td>\n",
       "      <td>0.289261</td>\n",
       "      <td>0.289261</td>\n",
       "      <td>0.031915</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.581829</td>\n",
       "      <td>0.037771</td>\n",
       "      <td>0.037771</td>\n",
       "      <td>0.019832</td>\n",
       "      <td>0.055925</td>\n",
       "      <td>0.055925</td>\n",
       "      <td>0.367429</td>\n",
       "      <td>-0.200531</td>\n",
       "      <td>0.055493</td>\n",
       "      <td>-0.107193</td>\n",
       "      <td>-0.066285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean_encoded_Airline</th>\n",
       "      <td>0.421194</td>\n",
       "      <td>0.638622</td>\n",
       "      <td>0.029206</td>\n",
       "      <td>0.433855</td>\n",
       "      <td>0.433855</td>\n",
       "      <td>0.033360</td>\n",
       "      <td>0.581829</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.258407</td>\n",
       "      <td>0.258407</td>\n",
       "      <td>0.158803</td>\n",
       "      <td>0.257210</td>\n",
       "      <td>0.257210</td>\n",
       "      <td>0.572079</td>\n",
       "      <td>-0.057231</td>\n",
       "      <td>0.047567</td>\n",
       "      <td>-0.183374</td>\n",
       "      <td>0.071402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_encoded_Source</th>\n",
       "      <td>0.571425</td>\n",
       "      <td>0.350856</td>\n",
       "      <td>0.160360</td>\n",
       "      <td>0.400089</td>\n",
       "      <td>0.400089</td>\n",
       "      <td>0.164188</td>\n",
       "      <td>0.037771</td>\n",
       "      <td>0.258407</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.303445</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.470222</td>\n",
       "      <td>-0.049791</td>\n",
       "      <td>0.067232</td>\n",
       "      <td>-0.595939</td>\n",
       "      <td>0.612529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_encoded_Destination</th>\n",
       "      <td>0.571425</td>\n",
       "      <td>0.350856</td>\n",
       "      <td>0.160360</td>\n",
       "      <td>0.400089</td>\n",
       "      <td>0.400089</td>\n",
       "      <td>0.164188</td>\n",
       "      <td>0.037771</td>\n",
       "      <td>0.258407</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.303445</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.470222</td>\n",
       "      <td>-0.049791</td>\n",
       "      <td>0.067232</td>\n",
       "      <td>-0.595939</td>\n",
       "      <td>0.612529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_encoded_Route</th>\n",
       "      <td>-0.205132</td>\n",
       "      <td>0.039251</td>\n",
       "      <td>0.105370</td>\n",
       "      <td>-0.110685</td>\n",
       "      <td>-0.110685</td>\n",
       "      <td>0.104308</td>\n",
       "      <td>0.019832</td>\n",
       "      <td>0.158803</td>\n",
       "      <td>0.303445</td>\n",
       "      <td>0.303445</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272866</td>\n",
       "      <td>0.272866</td>\n",
       "      <td>0.052597</td>\n",
       "      <td>0.194110</td>\n",
       "      <td>-0.195724</td>\n",
       "      <td>-0.001637</td>\n",
       "      <td>0.056397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean_encoded_Source</th>\n",
       "      <td>0.559061</td>\n",
       "      <td>0.359852</td>\n",
       "      <td>0.146240</td>\n",
       "      <td>0.414909</td>\n",
       "      <td>0.414909</td>\n",
       "      <td>0.150211</td>\n",
       "      <td>0.055925</td>\n",
       "      <td>0.257210</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.272866</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.482264</td>\n",
       "      <td>-0.059963</td>\n",
       "      <td>0.037782</td>\n",
       "      <td>-0.724390</td>\n",
       "      <td>0.496440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean_encoded_Destination</th>\n",
       "      <td>0.559061</td>\n",
       "      <td>0.359852</td>\n",
       "      <td>0.146240</td>\n",
       "      <td>0.414909</td>\n",
       "      <td>0.414909</td>\n",
       "      <td>0.150211</td>\n",
       "      <td>0.055925</td>\n",
       "      <td>0.257210</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.272866</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.482264</td>\n",
       "      <td>-0.059963</td>\n",
       "      <td>0.037782</td>\n",
       "      <td>-0.724390</td>\n",
       "      <td>0.496440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean_encoded_Route</th>\n",
       "      <td>0.806659</td>\n",
       "      <td>0.746261</td>\n",
       "      <td>-0.061108</td>\n",
       "      <td>0.671820</td>\n",
       "      <td>0.671820</td>\n",
       "      <td>-0.054674</td>\n",
       "      <td>0.367429</td>\n",
       "      <td>0.572079</td>\n",
       "      <td>0.470222</td>\n",
       "      <td>0.470222</td>\n",
       "      <td>0.052597</td>\n",
       "      <td>0.482264</td>\n",
       "      <td>0.482264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.058117</td>\n",
       "      <td>0.018220</td>\n",
       "      <td>-0.349316</td>\n",
       "      <td>0.206667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label_encoded_Airline</th>\n",
       "      <td>-0.194563</td>\n",
       "      <td>-0.036549</td>\n",
       "      <td>0.031828</td>\n",
       "      <td>-0.153788</td>\n",
       "      <td>-0.153788</td>\n",
       "      <td>0.030355</td>\n",
       "      <td>-0.200531</td>\n",
       "      <td>-0.057231</td>\n",
       "      <td>-0.049791</td>\n",
       "      <td>-0.049791</td>\n",
       "      <td>0.194110</td>\n",
       "      <td>-0.059963</td>\n",
       "      <td>-0.059963</td>\n",
       "      <td>-0.058117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.012048</td>\n",
       "      <td>0.068618</td>\n",
       "      <td>0.029601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label_encoded_Source</th>\n",
       "      <td>0.193899</td>\n",
       "      <td>0.013596</td>\n",
       "      <td>0.178190</td>\n",
       "      <td>0.162560</td>\n",
       "      <td>0.162560</td>\n",
       "      <td>0.179744</td>\n",
       "      <td>0.055493</td>\n",
       "      <td>0.047567</td>\n",
       "      <td>0.067232</td>\n",
       "      <td>0.067232</td>\n",
       "      <td>-0.195724</td>\n",
       "      <td>0.037782</td>\n",
       "      <td>0.037782</td>\n",
       "      <td>0.018220</td>\n",
       "      <td>-0.012048</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.432494</td>\n",
       "      <td>0.403561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label_encoded_Destination</th>\n",
       "      <td>-0.422555</td>\n",
       "      <td>-0.260673</td>\n",
       "      <td>-0.146161</td>\n",
       "      <td>-0.383666</td>\n",
       "      <td>-0.383666</td>\n",
       "      <td>-0.149833</td>\n",
       "      <td>-0.107193</td>\n",
       "      <td>-0.183374</td>\n",
       "      <td>-0.595939</td>\n",
       "      <td>-0.595939</td>\n",
       "      <td>-0.001637</td>\n",
       "      <td>-0.724390</td>\n",
       "      <td>-0.724390</td>\n",
       "      <td>-0.349316</td>\n",
       "      <td>0.068618</td>\n",
       "      <td>-0.432494</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.229317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label_encoded_Route</th>\n",
       "      <td>0.441153</td>\n",
       "      <td>0.154164</td>\n",
       "      <td>0.249640</td>\n",
       "      <td>0.273175</td>\n",
       "      <td>0.273175</td>\n",
       "      <td>0.252252</td>\n",
       "      <td>-0.066285</td>\n",
       "      <td>0.071402</td>\n",
       "      <td>0.612529</td>\n",
       "      <td>0.612529</td>\n",
       "      <td>0.056397</td>\n",
       "      <td>0.496440</td>\n",
       "      <td>0.496440</td>\n",
       "      <td>0.206667</td>\n",
       "      <td>0.029601</td>\n",
       "      <td>0.403561</td>\n",
       "      <td>-0.229317</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Total_Stops     Price  DepartureDateTime  \\\n",
       "Total_Stops                   1.000000  0.601978           0.032399   \n",
       "Price                         0.601978  1.000000          -0.149351   \n",
       "DepartureDateTime             0.032399 -0.149351           1.000000   \n",
       "Duration_min                  0.727930  0.501597          -0.003145   \n",
       "Duration_timedelta            0.727930  0.501597          -0.003145   \n",
       "ArrivalDateTime               0.039369 -0.144545           0.999954   \n",
       "Freq_encoded_Airline          0.211636  0.371569           0.029146   \n",
       "Mean_encoded_Airline          0.421194  0.638622           0.029206   \n",
       "Freq_encoded_Source           0.571425  0.350856           0.160360   \n",
       "Freq_encoded_Destination      0.571425  0.350856           0.160360   \n",
       "Freq_encoded_Route           -0.205132  0.039251           0.105370   \n",
       "Mean_encoded_Source           0.559061  0.359852           0.146240   \n",
       "Mean_encoded_Destination      0.559061  0.359852           0.146240   \n",
       "Mean_encoded_Route            0.806659  0.746261          -0.061108   \n",
       "Label_encoded_Airline        -0.194563 -0.036549           0.031828   \n",
       "Label_encoded_Source          0.193899  0.013596           0.178190   \n",
       "Label_encoded_Destination    -0.422555 -0.260673          -0.146161   \n",
       "Label_encoded_Route           0.441153  0.154164           0.249640   \n",
       "\n",
       "                           Duration_min  Duration_timedelta  ArrivalDateTime  \\\n",
       "Total_Stops                    0.727930            0.727930         0.039369   \n",
       "Price                          0.501597            0.501597        -0.144545   \n",
       "DepartureDateTime             -0.003145           -0.003145         0.999954   \n",
       "Duration_min                   1.000000            1.000000         0.006431   \n",
       "Duration_timedelta             1.000000            1.000000         0.006431   \n",
       "ArrivalDateTime                0.006431            0.006431         1.000000   \n",
       "Freq_encoded_Airline           0.289261            0.289261         0.031915   \n",
       "Mean_encoded_Airline           0.433855            0.433855         0.033360   \n",
       "Freq_encoded_Source            0.400089            0.400089         0.164188   \n",
       "Freq_encoded_Destination       0.400089            0.400089         0.164188   \n",
       "Freq_encoded_Route            -0.110685           -0.110685         0.104308   \n",
       "Mean_encoded_Source            0.414909            0.414909         0.150211   \n",
       "Mean_encoded_Destination       0.414909            0.414909         0.150211   \n",
       "Mean_encoded_Route             0.671820            0.671820        -0.054674   \n",
       "Label_encoded_Airline         -0.153788           -0.153788         0.030355   \n",
       "Label_encoded_Source           0.162560            0.162560         0.179744   \n",
       "Label_encoded_Destination     -0.383666           -0.383666        -0.149833   \n",
       "Label_encoded_Route            0.273175            0.273175         0.252252   \n",
       "\n",
       "                           Freq_encoded_Airline  Mean_encoded_Airline  \\\n",
       "Total_Stops                            0.211636              0.421194   \n",
       "Price                                  0.371569              0.638622   \n",
       "DepartureDateTime                      0.029146              0.029206   \n",
       "Duration_min                           0.289261              0.433855   \n",
       "Duration_timedelta                     0.289261              0.433855   \n",
       "ArrivalDateTime                        0.031915              0.033360   \n",
       "Freq_encoded_Airline                   1.000000              0.581829   \n",
       "Mean_encoded_Airline                   0.581829              1.000000   \n",
       "Freq_encoded_Source                    0.037771              0.258407   \n",
       "Freq_encoded_Destination               0.037771              0.258407   \n",
       "Freq_encoded_Route                     0.019832              0.158803   \n",
       "Mean_encoded_Source                    0.055925              0.257210   \n",
       "Mean_encoded_Destination               0.055925              0.257210   \n",
       "Mean_encoded_Route                     0.367429              0.572079   \n",
       "Label_encoded_Airline                 -0.200531             -0.057231   \n",
       "Label_encoded_Source                   0.055493              0.047567   \n",
       "Label_encoded_Destination             -0.107193             -0.183374   \n",
       "Label_encoded_Route                   -0.066285              0.071402   \n",
       "\n",
       "                           Freq_encoded_Source  Freq_encoded_Destination  \\\n",
       "Total_Stops                           0.571425                  0.571425   \n",
       "Price                                 0.350856                  0.350856   \n",
       "DepartureDateTime                     0.160360                  0.160360   \n",
       "Duration_min                          0.400089                  0.400089   \n",
       "Duration_timedelta                    0.400089                  0.400089   \n",
       "ArrivalDateTime                       0.164188                  0.164188   \n",
       "Freq_encoded_Airline                  0.037771                  0.037771   \n",
       "Mean_encoded_Airline                  0.258407                  0.258407   \n",
       "Freq_encoded_Source                   1.000000                  1.000000   \n",
       "Freq_encoded_Destination              1.000000                  1.000000   \n",
       "Freq_encoded_Route                    0.303445                  0.303445   \n",
       "Mean_encoded_Source                   0.975000                  0.975000   \n",
       "Mean_encoded_Destination              0.975000                  0.975000   \n",
       "Mean_encoded_Route                    0.470222                  0.470222   \n",
       "Label_encoded_Airline                -0.049791                 -0.049791   \n",
       "Label_encoded_Source                  0.067232                  0.067232   \n",
       "Label_encoded_Destination            -0.595939                 -0.595939   \n",
       "Label_encoded_Route                   0.612529                  0.612529   \n",
       "\n",
       "                           Freq_encoded_Route  Mean_encoded_Source  \\\n",
       "Total_Stops                         -0.205132             0.559061   \n",
       "Price                                0.039251             0.359852   \n",
       "DepartureDateTime                    0.105370             0.146240   \n",
       "Duration_min                        -0.110685             0.414909   \n",
       "Duration_timedelta                  -0.110685             0.414909   \n",
       "ArrivalDateTime                      0.104308             0.150211   \n",
       "Freq_encoded_Airline                 0.019832             0.055925   \n",
       "Mean_encoded_Airline                 0.158803             0.257210   \n",
       "Freq_encoded_Source                  0.303445             0.975000   \n",
       "Freq_encoded_Destination             0.303445             0.975000   \n",
       "Freq_encoded_Route                   1.000000             0.272866   \n",
       "Mean_encoded_Source                  0.272866             1.000000   \n",
       "Mean_encoded_Destination             0.272866             1.000000   \n",
       "Mean_encoded_Route                   0.052597             0.482264   \n",
       "Label_encoded_Airline                0.194110            -0.059963   \n",
       "Label_encoded_Source                -0.195724             0.037782   \n",
       "Label_encoded_Destination           -0.001637            -0.724390   \n",
       "Label_encoded_Route                  0.056397             0.496440   \n",
       "\n",
       "                           Mean_encoded_Destination  Mean_encoded_Route  \\\n",
       "Total_Stops                                0.559061            0.806659   \n",
       "Price                                      0.359852            0.746261   \n",
       "DepartureDateTime                          0.146240           -0.061108   \n",
       "Duration_min                               0.414909            0.671820   \n",
       "Duration_timedelta                         0.414909            0.671820   \n",
       "ArrivalDateTime                            0.150211           -0.054674   \n",
       "Freq_encoded_Airline                       0.055925            0.367429   \n",
       "Mean_encoded_Airline                       0.257210            0.572079   \n",
       "Freq_encoded_Source                        0.975000            0.470222   \n",
       "Freq_encoded_Destination                   0.975000            0.470222   \n",
       "Freq_encoded_Route                         0.272866            0.052597   \n",
       "Mean_encoded_Source                        1.000000            0.482264   \n",
       "Mean_encoded_Destination                   1.000000            0.482264   \n",
       "Mean_encoded_Route                         0.482264            1.000000   \n",
       "Label_encoded_Airline                     -0.059963           -0.058117   \n",
       "Label_encoded_Source                       0.037782            0.018220   \n",
       "Label_encoded_Destination                 -0.724390           -0.349316   \n",
       "Label_encoded_Route                        0.496440            0.206667   \n",
       "\n",
       "                           Label_encoded_Airline  Label_encoded_Source  \\\n",
       "Total_Stops                            -0.194563              0.193899   \n",
       "Price                                  -0.036549              0.013596   \n",
       "DepartureDateTime                       0.031828              0.178190   \n",
       "Duration_min                           -0.153788              0.162560   \n",
       "Duration_timedelta                     -0.153788              0.162560   \n",
       "ArrivalDateTime                         0.030355              0.179744   \n",
       "Freq_encoded_Airline                   -0.200531              0.055493   \n",
       "Mean_encoded_Airline                   -0.057231              0.047567   \n",
       "Freq_encoded_Source                    -0.049791              0.067232   \n",
       "Freq_encoded_Destination               -0.049791              0.067232   \n",
       "Freq_encoded_Route                      0.194110             -0.195724   \n",
       "Mean_encoded_Source                    -0.059963              0.037782   \n",
       "Mean_encoded_Destination               -0.059963              0.037782   \n",
       "Mean_encoded_Route                     -0.058117              0.018220   \n",
       "Label_encoded_Airline                   1.000000             -0.012048   \n",
       "Label_encoded_Source                   -0.012048              1.000000   \n",
       "Label_encoded_Destination               0.068618             -0.432494   \n",
       "Label_encoded_Route                     0.029601              0.403561   \n",
       "\n",
       "                           Label_encoded_Destination  Label_encoded_Route  \n",
       "Total_Stops                                -0.422555             0.441153  \n",
       "Price                                      -0.260673             0.154164  \n",
       "DepartureDateTime                          -0.146161             0.249640  \n",
       "Duration_min                               -0.383666             0.273175  \n",
       "Duration_timedelta                         -0.383666             0.273175  \n",
       "ArrivalDateTime                            -0.149833             0.252252  \n",
       "Freq_encoded_Airline                       -0.107193            -0.066285  \n",
       "Mean_encoded_Airline                       -0.183374             0.071402  \n",
       "Freq_encoded_Source                        -0.595939             0.612529  \n",
       "Freq_encoded_Destination                   -0.595939             0.612529  \n",
       "Freq_encoded_Route                         -0.001637             0.056397  \n",
       "Mean_encoded_Source                        -0.724390             0.496440  \n",
       "Mean_encoded_Destination                   -0.724390             0.496440  \n",
       "Mean_encoded_Route                         -0.349316             0.206667  \n",
       "Label_encoded_Airline                       0.068618             0.029601  \n",
       "Label_encoded_Source                       -0.432494             0.403561  \n",
       "Label_encoded_Destination                   1.000000            -0.229317  \n",
       "Label_encoded_Route                        -0.229317             1.000000  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "280bb859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import SplineTransformer\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "def regression(X_train, X_test, y_train, y_test):\n",
    "    ## Baseline model\n",
    "    reg = linear_model.LinearRegression()\n",
    "    reg.fit(X_train,y_train)\n",
    "    print(metrics.r2_score(y_train,reg.predict(X_train)), metrics.r2_score(y_test,reg.predict(X_test)))\n",
    "    return reg\n",
    "\n",
    "def knearestneighbour(X_train, X_test, y_train, y_test):\n",
    "    knn_regressor = KNeighborsRegressor(n_neighbors=10)\n",
    "    knn_regressor.fit(X_train, y_train)\n",
    "    print(metrics.r2_score(y_train,knn_regressor.predict(X_train)),metrics.r2_score(y_test,knn_regressor.predict(X_test)))\n",
    "    return knn_regressor\n",
    "\n",
    "def decisiontree(X_train, X_test, y_train, y_test):\n",
    "    tree = DecisionTreeRegressor(max_depth=10)\n",
    "    tree.fit(X_train,y_train)\n",
    "    print(metrics.r2_score(y_train,tree.predict(X_train)),metrics.r2_score(y_test,tree.predict(X_test)))\n",
    "    return tree\n",
    "\n",
    "def randomForest(X_train, X_test, y_train, y_test):\n",
    "    random_regressor = RandomForestRegressor(n_estimators=500, min_samples_split=10,min_samples_leaf=2)\n",
    "    random_regressor.fit(X_train, y_train)\n",
    "    print(metrics.r2_score(y_train,random_regressor.predict(X_train)),metrics.r2_score(y_test,random_regressor.predict(X_test)))\n",
    "    return random_regressor\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "def xgboost(X_train, X_test, y_train, y_test):\n",
    "    xgboost_regressor = XGBRegressor()\n",
    "    xgboost_regressor.fit(X_train, y_train)\n",
    "    print(metrics.r2_score(y_train,xgboost_regressor.predict(X_train)),metrics.r2_score(y_test,xgboost_regressor.predict(X_test)))\n",
    "    return xgboost_regressor\n",
    "\n",
    "from catboost import  CatBoostRegressor\n",
    "def catboost(X_train, X_test, y_train, y_test):\n",
    "    catboost_regressor = CatBoostRegressor(verbose=False)\n",
    "    catboost_regressor.fit(X_train, y_train)\n",
    "    print(metrics.r2_score(y_train,catboost_regressor.predict(X_train)),metrics.r2_score(y_test,catboost_regressor.predict(X_test)))\n",
    "    return catboost_regressor\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "def gboost(X_train, X_test, y_train, y_test):\n",
    "    gboost_regressor = GradientBoostingRegressor()\n",
    "    gboost_regressor.fit(X_train, y_train)\n",
    "    print(metrics.r2_score(y_train,gboost_regressor.predict(X_train)),metrics.r2_score(y_test,gboost_regressor.predict(X_test)))\n",
    "    return gboost_regressor\n",
    "\n",
    "\n",
    "def train(X,y,modelType):\n",
    "    # Split your dataset into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    model = modelType(X_train, X_test, y_train, y_test)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3a306b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Price</th>\n",
       "      <th>DepartureDateTime</th>\n",
       "      <th>Duration_min</th>\n",
       "      <th>Duration_timedelta</th>\n",
       "      <th>ArrivalDateTime</th>\n",
       "      <th>Freq_encoded_Airline</th>\n",
       "      <th>Mean_encoded_Airline</th>\n",
       "      <th>Freq_encoded_Source</th>\n",
       "      <th>Freq_encoded_Destination</th>\n",
       "      <th>Freq_encoded_Route</th>\n",
       "      <th>Mean_encoded_Source</th>\n",
       "      <th>Mean_encoded_Destination</th>\n",
       "      <th>Mean_encoded_Route</th>\n",
       "      <th>Label_encoded_Airline</th>\n",
       "      <th>Label_encoded_Source</th>\n",
       "      <th>Label_encoded_Destination</th>\n",
       "      <th>Label_encoded_Route</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3897</td>\n",
       "      <td>2019-03-24 22:20:00</td>\n",
       "      <td>170</td>\n",
       "      <td>0 days 02:50:00</td>\n",
       "      <td>2019-03-25 01:10:00</td>\n",
       "      <td>0.195297</td>\n",
       "      <td>5668.469897</td>\n",
       "      <td>0.208106</td>\n",
       "      <td>0.208106</td>\n",
       "      <td>0.146640</td>\n",
       "      <td>8024.689940</td>\n",
       "      <td>8024.689940</td>\n",
       "      <td>5551.593220</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7662</td>\n",
       "      <td>2019-05-01 05:50:00</td>\n",
       "      <td>445</td>\n",
       "      <td>0 days 07:25:00</td>\n",
       "      <td>2019-05-01 13:15:00</td>\n",
       "      <td>0.162030</td>\n",
       "      <td>9555.382891</td>\n",
       "      <td>0.273396</td>\n",
       "      <td>0.273396</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>9143.083566</td>\n",
       "      <td>9143.083566</td>\n",
       "      <td>7369.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total_Stops  Price   DepartureDateTime  Duration_min Duration_timedelta  \\\n",
       "0          0.0   3897 2019-03-24 22:20:00           170    0 days 02:50:00   \n",
       "1          2.0   7662 2019-05-01 05:50:00           445    0 days 07:25:00   \n",
       "\n",
       "      ArrivalDateTime  Freq_encoded_Airline  Mean_encoded_Airline  \\\n",
       "0 2019-03-25 01:10:00              0.195297           5668.469897   \n",
       "1 2019-05-01 13:15:00              0.162030           9555.382891   \n",
       "\n",
       "   Freq_encoded_Source  Freq_encoded_Destination  Freq_encoded_Route  \\\n",
       "0             0.208106                  0.208106            0.146640   \n",
       "1             0.273396                  0.273396            0.000574   \n",
       "\n",
       "   Mean_encoded_Source  Mean_encoded_Destination  Mean_encoded_Route  \\\n",
       "0          8024.689940               8024.689940         5551.593220   \n",
       "1          9143.083566               9143.083566         7369.166667   \n",
       "\n",
       "   Label_encoded_Airline  Label_encoded_Source  Label_encoded_Destination  \\\n",
       "0                      3                     0                          2   \n",
       "1                      1                     3                          0   \n",
       "\n",
       "   Label_encoded_Route  \n",
       "0                 18.0  \n",
       "1                 84.0  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c5d5392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Price','DepartureDateTime','Duration_timedelta','ArrivalDateTime'])\n",
    "y = df['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "06a5ec8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[95], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.33\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      2\u001b[0m reg \u001b[38;5;241m=\u001b[39m linear_model\u001b[38;5;241m.\u001b[39mLinearRegression()\n\u001b[1;32m----> 3\u001b[0m reg\u001b[38;5;241m.\u001b[39mfit(X_train,y_train)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(metrics\u001b[38;5;241m.\u001b[39mr2_score(y_train,reg\u001b[38;5;241m.\u001b[39mpredict(X_train)), metrics\u001b[38;5;241m.\u001b[39mr2_score(y_test,reg\u001b[38;5;241m.\u001b[39mpredict(X_test)))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:678\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    674\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    676\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 678\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    679\u001b[0m     X, y, accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse, y_numeric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    680\u001b[0m )\n\u001b[0;32m    682\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1145\u001b[0m     )\n\u001b[1;32m-> 1147\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1148\u001b[0m     X,\n\u001b[0;32m   1149\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1150\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1151\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1152\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1153\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1154\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m   1155\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1156\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1157\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1158\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1159\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1160\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[0;32m   1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    954\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    955\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    956\u001b[0m         )\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 959\u001b[0m         _assert_all_finite(\n\u001b[0;32m    960\u001b[0m             array,\n\u001b[0;32m    961\u001b[0m             input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    962\u001b[0m             estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    963\u001b[0m             allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    964\u001b[0m         )\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n\u001b[0;32m    125\u001b[0m     X,\n\u001b[0;32m    126\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[0;32m    127\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[0;32m    128\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[0;32m    129\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    130\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    131\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m     )\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X_train,y_train)\n",
    "print(metrics.r2_score(y_train,reg.predict(X_train)), metrics.r2_score(y_test,reg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40beb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(X,y,regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2ff432",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(X,y,knearestneighbour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7730d93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(X,y,decisiontree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d635996",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(X,y,randomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34246e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(X,y,xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970c2d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(X,y,catboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88ce58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(X,y,gboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaeac0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert all data into numerical form to obtain your baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a666b7d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[96], line 32\u001b[0m\n\u001b[0;32m     28\u001b[0m     df_vif \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVIF\u001b[39m\u001b[38;5;124m'\u001b[39m: vif_dict, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTolerance\u001b[39m\u001b[38;5;124m'\u001b[39m: tolerance_dict})\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_vif\n\u001b[1;32m---> 32\u001b[0m df_vif\u001b[38;5;241m=\u001b[39m sklearn_vif(exogs\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mcolumns, data\u001b[38;5;241m=\u001b[39mX)\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVIF\u001b[39m\u001b[38;5;124m'\u001b[39m,ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[96], line 17\u001b[0m, in \u001b[0;36msklearn_vif\u001b[1;34m(exogs, data)\u001b[0m\n\u001b[0;32m     14\u001b[0m X, y \u001b[38;5;241m=\u001b[39m data[not_exog], data[exog]\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# extract r-squared from the fit\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m r_squared \u001b[38;5;241m=\u001b[39m LinearRegression()\u001b[38;5;241m.\u001b[39mfit(X, y)\u001b[38;5;241m.\u001b[39mscore(X, y)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# calculate VIF\u001b[39;00m\n\u001b[0;32m     20\u001b[0m vif \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m r_squared)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:678\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    674\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    676\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 678\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    679\u001b[0m     X, y, accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse, y_numeric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    680\u001b[0m )\n\u001b[0;32m    682\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1145\u001b[0m     )\n\u001b[1;32m-> 1147\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1148\u001b[0m     X,\n\u001b[0;32m   1149\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1150\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1151\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1152\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1153\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1154\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m   1155\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1156\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1157\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1158\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1159\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1160\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[0;32m   1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    954\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    955\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    956\u001b[0m         )\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 959\u001b[0m         _assert_all_finite(\n\u001b[0;32m    960\u001b[0m             array,\n\u001b[0;32m    961\u001b[0m             input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    962\u001b[0m             estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    963\u001b[0m             allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    964\u001b[0m         )\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n\u001b[0;32m    125\u001b[0m     X,\n\u001b[0;32m    126\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[0;32m    127\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[0;32m    128\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[0;32m    129\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    130\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    131\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m     )\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def sklearn_vif(exogs, data):\n",
    "    '''\n",
    "    This function calculates variance inflation function in sklearn way. \n",
    "     It is a comparatively faster process.\n",
    "    '''\n",
    "    # initialize dictionaries\n",
    "    vif_dict, tolerance_dict = {}, {}\n",
    "\n",
    "    # form input data for each exogenous variable\n",
    "    for exog in exogs:\n",
    "        not_exog = [i for i in exogs if i != exog]\n",
    "        X, y = data[not_exog], data[exog]\n",
    "\n",
    "        # extract r-squared from the fit\n",
    "        r_squared = LinearRegression().fit(X, y).score(X, y)\n",
    "\n",
    "        # calculate VIF\n",
    "        vif = 1/(1 - r_squared)\n",
    "        vif_dict[exog] = vif\n",
    "\n",
    "        # calculate tolerance\n",
    "        tolerance = 1 - r_squared\n",
    "        tolerance_dict[exog] = tolerance\n",
    "\n",
    "    # return VIF DataFrame\n",
    "    df_vif = pd.DataFrame({'VIF': vif_dict, 'Tolerance': tolerance_dict})\n",
    "\n",
    "    return df_vif\n",
    "\n",
    "df_vif= sklearn_vif(exogs=X.columns, data=X).sort_values(by='VIF',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aaeb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIF >= 10 shows high collinearity\n",
    "df_vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "381f985e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Total_Stops', 'Duration_min', 'Freq_encoded_Airline',\n",
       "       'Mean_encoded_Airline', 'Freq_encoded_Source',\n",
       "       'Freq_encoded_Destination', 'Freq_encoded_Route', 'Mean_encoded_Source',\n",
       "       'Mean_encoded_Destination', 'Mean_encoded_Route',\n",
       "       'Label_encoded_Airline', 'Label_encoded_Source',\n",
       "       'Label_encoded_Destination', 'Label_encoded_Route'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c1ae729d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[98], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m vif_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal_Stops\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDuration_min\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFreq_encoded_Airline\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      2\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMean_encoded_Airline\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#             'Freq_encoded_Source',\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel_encoded_Airline\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel_encoded_Source\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel_encoded_Destination\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel_encoded_Route\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     10\u001b[0m X[vif_cols]\n\u001b[1;32m---> 11\u001b[0m df_vif\u001b[38;5;241m=\u001b[39m sklearn_vif(exogs\u001b[38;5;241m=\u001b[39mvif_cols, data\u001b[38;5;241m=\u001b[39mX[vif_cols])\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVIF\u001b[39m\u001b[38;5;124m'\u001b[39m,ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     12\u001b[0m df_vif\n",
      "Cell \u001b[1;32mIn[96], line 17\u001b[0m, in \u001b[0;36msklearn_vif\u001b[1;34m(exogs, data)\u001b[0m\n\u001b[0;32m     14\u001b[0m X, y \u001b[38;5;241m=\u001b[39m data[not_exog], data[exog]\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# extract r-squared from the fit\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m r_squared \u001b[38;5;241m=\u001b[39m LinearRegression()\u001b[38;5;241m.\u001b[39mfit(X, y)\u001b[38;5;241m.\u001b[39mscore(X, y)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# calculate VIF\u001b[39;00m\n\u001b[0;32m     20\u001b[0m vif \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m r_squared)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:678\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    674\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    676\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 678\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    679\u001b[0m     X, y, accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse, y_numeric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    680\u001b[0m )\n\u001b[0;32m    682\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1145\u001b[0m     )\n\u001b[1;32m-> 1147\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1148\u001b[0m     X,\n\u001b[0;32m   1149\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1150\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1151\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1152\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1153\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1154\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m   1155\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1156\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1157\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1158\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1159\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1160\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[0;32m   1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    954\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    955\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    956\u001b[0m         )\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 959\u001b[0m         _assert_all_finite(\n\u001b[0;32m    960\u001b[0m             array,\n\u001b[0;32m    961\u001b[0m             input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    962\u001b[0m             estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    963\u001b[0m             allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    964\u001b[0m         )\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n\u001b[0;32m    125\u001b[0m     X,\n\u001b[0;32m    126\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[0;32m    127\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[0;32m    128\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[0;32m    129\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    130\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    131\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m     )\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "vif_cols = ['Total_Stops', 'Duration_min', 'Freq_encoded_Airline',\n",
    "       'Mean_encoded_Airline', \n",
    "#             'Freq_encoded_Source',\n",
    "       'Freq_encoded_Destination', 'Freq_encoded_Route', \n",
    "#             'Mean_encoded_Source',\n",
    "#        'Mean_encoded_Destination',\n",
    "            'Mean_encoded_Route',\n",
    "       'Label_encoded_Airline', 'Label_encoded_Source',\n",
    "       'Label_encoded_Destination', 'Label_encoded_Route']\n",
    "X[vif_cols]\n",
    "df_vif= sklearn_vif(exogs=vif_cols, data=X[vif_cols]).sort_values(by='VIF',ascending=False)\n",
    "df_vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5970fc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(X[vif_cols],y,regression)\n",
    "train(X[vif_cols],y,knearestneighbour)\n",
    "train(X[vif_cols],y,decisiontree)\n",
    "train(X[vif_cols],y,randomForest)\n",
    "train(X[vif_cols],y,xgboost)\n",
    "train(X[vif_cols],y,gboost)\n",
    "train(X[vif_cols],y,catboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02158b01",
   "metadata": {},
   "source": [
    "## Scaling and Outlier treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "30b850a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[vif_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4f42a4d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m X_transform \u001b[38;5;241m=\u001b[39m RobustScaler()\u001b[38;5;241m.\u001b[39mfit_transform(X)\n\u001b[0;32m      4\u001b[0m X_transformed \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X_transform,columns\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m----> 6\u001b[0m train(X_transformed,y,regression)\n\u001b[0;32m      7\u001b[0m train(X_transformed,y,knearestneighbour)\n\u001b[0;32m      8\u001b[0m train(X_transformed,y,decisiontree)\n",
      "Cell \u001b[1;32mIn[92], line 71\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(X, y, modelType)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(X,y,modelType):\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# Split your dataset into train and test\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.33\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 71\u001b[0m     model \u001b[38;5;241m=\u001b[39m modelType(X_train, X_test, y_train, y_test)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "Cell \u001b[1;32mIn[92], line 24\u001b[0m, in \u001b[0;36mregression\u001b[1;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mregression\u001b[39m(X_train, X_test, y_train, y_test):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m## Baseline model\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     reg \u001b[38;5;241m=\u001b[39m linear_model\u001b[38;5;241m.\u001b[39mLinearRegression()\n\u001b[1;32m---> 24\u001b[0m     reg\u001b[38;5;241m.\u001b[39mfit(X_train,y_train)\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(metrics\u001b[38;5;241m.\u001b[39mr2_score(y_train,reg\u001b[38;5;241m.\u001b[39mpredict(X_train)), metrics\u001b[38;5;241m.\u001b[39mr2_score(y_test,reg\u001b[38;5;241m.\u001b[39mpredict(X_test)))\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reg\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:678\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    674\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    676\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 678\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    679\u001b[0m     X, y, accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse, y_numeric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    680\u001b[0m )\n\u001b[0;32m    682\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1145\u001b[0m     )\n\u001b[1;32m-> 1147\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1148\u001b[0m     X,\n\u001b[0;32m   1149\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1150\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1151\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1152\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1153\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1154\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m   1155\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1156\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1157\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1158\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1159\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1160\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[0;32m   1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    954\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    955\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    956\u001b[0m         )\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 959\u001b[0m         _assert_all_finite(\n\u001b[0;32m    960\u001b[0m             array,\n\u001b[0;32m    961\u001b[0m             input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    962\u001b[0m             estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    963\u001b[0m             allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    964\u001b[0m         )\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n\u001b[0;32m    125\u001b[0m     X,\n\u001b[0;32m    126\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[0;32m    127\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[0;32m    128\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[0;32m    129\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    130\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    131\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m     )\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "X_transform = RobustScaler().fit_transform(X)\n",
    "X_transformed = pd.DataFrame(X_transform,columns=X.columns)\n",
    "\n",
    "train(X_transformed,y,regression)\n",
    "train(X_transformed,y,knearestneighbour)\n",
    "train(X_transformed,y,decisiontree)\n",
    "train(X_transformed,y,randomForest)\n",
    "train(X_transformed,y,xgboost)\n",
    "train(X_transformed,y,gboost)\n",
    "train(X_transformed,y,catboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d243f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed =X_transformed.copy(deep=True)\n",
    "df_transformed['Price'] = y\n",
    "df_transformed.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd15644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "X_transform = PowerTransformer().fit_transform(X)\n",
    "X_transformed = pd.DataFrame(X_transform,columns=X.columns)\n",
    "\n",
    "train(X_transformed,y,regression)\n",
    "train(X_transformed,y,knearestneighbour)\n",
    "train(X_transformed,y,decisiontree)\n",
    "train(X_transformed,y,randomForest)\n",
    "train(X_transformed,y,xgboost)\n",
    "train(X_transformed,y,gboost)\n",
    "train(X_transformed,y,catboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "69f9117c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Duration_min</th>\n",
       "      <th>Freq_encoded_Airline</th>\n",
       "      <th>Mean_encoded_Airline</th>\n",
       "      <th>Freq_encoded_Destination</th>\n",
       "      <th>Freq_encoded_Route</th>\n",
       "      <th>Mean_encoded_Route</th>\n",
       "      <th>Label_encoded_Airline</th>\n",
       "      <th>Label_encoded_Source</th>\n",
       "      <th>Label_encoded_Destination</th>\n",
       "      <th>Label_encoded_Route</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total_Stops</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727930</td>\n",
       "      <td>0.211636</td>\n",
       "      <td>0.421194</td>\n",
       "      <td>0.571425</td>\n",
       "      <td>-0.205132</td>\n",
       "      <td>0.806659</td>\n",
       "      <td>-0.194563</td>\n",
       "      <td>0.193899</td>\n",
       "      <td>-0.422555</td>\n",
       "      <td>0.441153</td>\n",
       "      <td>0.020604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Duration_min</th>\n",
       "      <td>0.727930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.289261</td>\n",
       "      <td>0.433855</td>\n",
       "      <td>0.400089</td>\n",
       "      <td>-0.110685</td>\n",
       "      <td>0.671820</td>\n",
       "      <td>-0.153788</td>\n",
       "      <td>0.162560</td>\n",
       "      <td>-0.383666</td>\n",
       "      <td>0.273175</td>\n",
       "      <td>0.010392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_encoded_Airline</th>\n",
       "      <td>0.211636</td>\n",
       "      <td>0.289261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.581829</td>\n",
       "      <td>0.037771</td>\n",
       "      <td>0.019832</td>\n",
       "      <td>0.367429</td>\n",
       "      <td>-0.200531</td>\n",
       "      <td>0.055493</td>\n",
       "      <td>-0.107193</td>\n",
       "      <td>-0.066285</td>\n",
       "      <td>0.009577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean_encoded_Airline</th>\n",
       "      <td>0.421194</td>\n",
       "      <td>0.433855</td>\n",
       "      <td>0.581829</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.258407</td>\n",
       "      <td>0.158803</td>\n",
       "      <td>0.572079</td>\n",
       "      <td>-0.057231</td>\n",
       "      <td>0.047567</td>\n",
       "      <td>-0.183374</td>\n",
       "      <td>0.071402</td>\n",
       "      <td>0.031378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_encoded_Destination</th>\n",
       "      <td>0.571425</td>\n",
       "      <td>0.400089</td>\n",
       "      <td>0.037771</td>\n",
       "      <td>0.258407</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.303445</td>\n",
       "      <td>0.470222</td>\n",
       "      <td>-0.049791</td>\n",
       "      <td>0.067232</td>\n",
       "      <td>-0.595939</td>\n",
       "      <td>0.612529</td>\n",
       "      <td>0.027984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_encoded_Route</th>\n",
       "      <td>-0.205132</td>\n",
       "      <td>-0.110685</td>\n",
       "      <td>0.019832</td>\n",
       "      <td>0.158803</td>\n",
       "      <td>0.303445</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052597</td>\n",
       "      <td>0.194110</td>\n",
       "      <td>-0.195724</td>\n",
       "      <td>-0.001637</td>\n",
       "      <td>0.056397</td>\n",
       "      <td>0.030701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean_encoded_Route</th>\n",
       "      <td>0.806659</td>\n",
       "      <td>0.671820</td>\n",
       "      <td>0.367429</td>\n",
       "      <td>0.572079</td>\n",
       "      <td>0.470222</td>\n",
       "      <td>0.052597</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.058117</td>\n",
       "      <td>0.018220</td>\n",
       "      <td>-0.349316</td>\n",
       "      <td>0.206667</td>\n",
       "      <td>0.039173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label_encoded_Airline</th>\n",
       "      <td>-0.194563</td>\n",
       "      <td>-0.153788</td>\n",
       "      <td>-0.200531</td>\n",
       "      <td>-0.057231</td>\n",
       "      <td>-0.049791</td>\n",
       "      <td>0.194110</td>\n",
       "      <td>-0.058117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.012048</td>\n",
       "      <td>0.068618</td>\n",
       "      <td>0.029601</td>\n",
       "      <td>0.011530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label_encoded_Source</th>\n",
       "      <td>0.193899</td>\n",
       "      <td>0.162560</td>\n",
       "      <td>0.055493</td>\n",
       "      <td>0.047567</td>\n",
       "      <td>0.067232</td>\n",
       "      <td>-0.195724</td>\n",
       "      <td>0.018220</td>\n",
       "      <td>-0.012048</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.432494</td>\n",
       "      <td>0.403561</td>\n",
       "      <td>-0.005722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label_encoded_Destination</th>\n",
       "      <td>-0.422555</td>\n",
       "      <td>-0.383666</td>\n",
       "      <td>-0.107193</td>\n",
       "      <td>-0.183374</td>\n",
       "      <td>-0.595939</td>\n",
       "      <td>-0.001637</td>\n",
       "      <td>-0.349316</td>\n",
       "      <td>0.068618</td>\n",
       "      <td>-0.432494</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.229317</td>\n",
       "      <td>-0.011623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label_encoded_Route</th>\n",
       "      <td>0.441153</td>\n",
       "      <td>0.273175</td>\n",
       "      <td>-0.066285</td>\n",
       "      <td>0.071402</td>\n",
       "      <td>0.612529</td>\n",
       "      <td>0.056397</td>\n",
       "      <td>0.206667</td>\n",
       "      <td>0.029601</td>\n",
       "      <td>0.403561</td>\n",
       "      <td>-0.229317</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <td>0.020604</td>\n",
       "      <td>0.010392</td>\n",
       "      <td>0.009577</td>\n",
       "      <td>0.031378</td>\n",
       "      <td>0.027984</td>\n",
       "      <td>0.030701</td>\n",
       "      <td>0.039173</td>\n",
       "      <td>0.011530</td>\n",
       "      <td>-0.005722</td>\n",
       "      <td>-0.011623</td>\n",
       "      <td>0.012640</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Total_Stops  Duration_min  Freq_encoded_Airline  \\\n",
       "Total_Stops                   1.000000      0.727930              0.211636   \n",
       "Duration_min                  0.727930      1.000000              0.289261   \n",
       "Freq_encoded_Airline          0.211636      0.289261              1.000000   \n",
       "Mean_encoded_Airline          0.421194      0.433855              0.581829   \n",
       "Freq_encoded_Destination      0.571425      0.400089              0.037771   \n",
       "Freq_encoded_Route           -0.205132     -0.110685              0.019832   \n",
       "Mean_encoded_Route            0.806659      0.671820              0.367429   \n",
       "Label_encoded_Airline        -0.194563     -0.153788             -0.200531   \n",
       "Label_encoded_Source          0.193899      0.162560              0.055493   \n",
       "Label_encoded_Destination    -0.422555     -0.383666             -0.107193   \n",
       "Label_encoded_Route           0.441153      0.273175             -0.066285   \n",
       "Price                         0.020604      0.010392              0.009577   \n",
       "\n",
       "                           Mean_encoded_Airline  Freq_encoded_Destination  \\\n",
       "Total_Stops                            0.421194                  0.571425   \n",
       "Duration_min                           0.433855                  0.400089   \n",
       "Freq_encoded_Airline                   0.581829                  0.037771   \n",
       "Mean_encoded_Airline                   1.000000                  0.258407   \n",
       "Freq_encoded_Destination               0.258407                  1.000000   \n",
       "Freq_encoded_Route                     0.158803                  0.303445   \n",
       "Mean_encoded_Route                     0.572079                  0.470222   \n",
       "Label_encoded_Airline                 -0.057231                 -0.049791   \n",
       "Label_encoded_Source                   0.047567                  0.067232   \n",
       "Label_encoded_Destination             -0.183374                 -0.595939   \n",
       "Label_encoded_Route                    0.071402                  0.612529   \n",
       "Price                                  0.031378                  0.027984   \n",
       "\n",
       "                           Freq_encoded_Route  Mean_encoded_Route  \\\n",
       "Total_Stops                         -0.205132            0.806659   \n",
       "Duration_min                        -0.110685            0.671820   \n",
       "Freq_encoded_Airline                 0.019832            0.367429   \n",
       "Mean_encoded_Airline                 0.158803            0.572079   \n",
       "Freq_encoded_Destination             0.303445            0.470222   \n",
       "Freq_encoded_Route                   1.000000            0.052597   \n",
       "Mean_encoded_Route                   0.052597            1.000000   \n",
       "Label_encoded_Airline                0.194110           -0.058117   \n",
       "Label_encoded_Source                -0.195724            0.018220   \n",
       "Label_encoded_Destination           -0.001637           -0.349316   \n",
       "Label_encoded_Route                  0.056397            0.206667   \n",
       "Price                                0.030701            0.039173   \n",
       "\n",
       "                           Label_encoded_Airline  Label_encoded_Source  \\\n",
       "Total_Stops                            -0.194563              0.193899   \n",
       "Duration_min                           -0.153788              0.162560   \n",
       "Freq_encoded_Airline                   -0.200531              0.055493   \n",
       "Mean_encoded_Airline                   -0.057231              0.047567   \n",
       "Freq_encoded_Destination               -0.049791              0.067232   \n",
       "Freq_encoded_Route                      0.194110             -0.195724   \n",
       "Mean_encoded_Route                     -0.058117              0.018220   \n",
       "Label_encoded_Airline                   1.000000             -0.012048   \n",
       "Label_encoded_Source                   -0.012048              1.000000   \n",
       "Label_encoded_Destination               0.068618             -0.432494   \n",
       "Label_encoded_Route                     0.029601              0.403561   \n",
       "Price                                   0.011530             -0.005722   \n",
       "\n",
       "                           Label_encoded_Destination  Label_encoded_Route  \\\n",
       "Total_Stops                                -0.422555             0.441153   \n",
       "Duration_min                               -0.383666             0.273175   \n",
       "Freq_encoded_Airline                       -0.107193            -0.066285   \n",
       "Mean_encoded_Airline                       -0.183374             0.071402   \n",
       "Freq_encoded_Destination                   -0.595939             0.612529   \n",
       "Freq_encoded_Route                         -0.001637             0.056397   \n",
       "Mean_encoded_Route                         -0.349316             0.206667   \n",
       "Label_encoded_Airline                       0.068618             0.029601   \n",
       "Label_encoded_Source                       -0.432494             0.403561   \n",
       "Label_encoded_Destination                   1.000000            -0.229317   \n",
       "Label_encoded_Route                        -0.229317             1.000000   \n",
       "Price                                      -0.011623             0.012640   \n",
       "\n",
       "                              Price  \n",
       "Total_Stops                0.020604  \n",
       "Duration_min               0.010392  \n",
       "Freq_encoded_Airline       0.009577  \n",
       "Mean_encoded_Airline       0.031378  \n",
       "Freq_encoded_Destination   0.027984  \n",
       "Freq_encoded_Route         0.030701  \n",
       "Mean_encoded_Route         0.039173  \n",
       "Label_encoded_Airline      0.011530  \n",
       "Label_encoded_Source      -0.005722  \n",
       "Label_encoded_Destination -0.011623  \n",
       "Label_encoded_Route        0.012640  \n",
       "Price                      1.000000  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed =X_transformed.copy(deep=True)\n",
    "df_transformed['Price'] = y\n",
    "df_transformed.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7266f68a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[102], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m X_transform \u001b[38;5;241m=\u001b[39m FunctionTransformer(np\u001b[38;5;241m.\u001b[39mlog1p)\u001b[38;5;241m.\u001b[39mfit_transform(X)\n\u001b[0;32m      4\u001b[0m X_transformed \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X_transform,columns\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m----> 7\u001b[0m train(X_transformed,y,regression)\n\u001b[0;32m      8\u001b[0m train(X_transformed,y,knearestneighbour)\n\u001b[0;32m      9\u001b[0m train(X_transformed,y,decisiontree)\n",
      "Cell \u001b[1;32mIn[92], line 71\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(X, y, modelType)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(X,y,modelType):\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# Split your dataset into train and test\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.33\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 71\u001b[0m     model \u001b[38;5;241m=\u001b[39m modelType(X_train, X_test, y_train, y_test)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "Cell \u001b[1;32mIn[92], line 24\u001b[0m, in \u001b[0;36mregression\u001b[1;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mregression\u001b[39m(X_train, X_test, y_train, y_test):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m## Baseline model\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     reg \u001b[38;5;241m=\u001b[39m linear_model\u001b[38;5;241m.\u001b[39mLinearRegression()\n\u001b[1;32m---> 24\u001b[0m     reg\u001b[38;5;241m.\u001b[39mfit(X_train,y_train)\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(metrics\u001b[38;5;241m.\u001b[39mr2_score(y_train,reg\u001b[38;5;241m.\u001b[39mpredict(X_train)), metrics\u001b[38;5;241m.\u001b[39mr2_score(y_test,reg\u001b[38;5;241m.\u001b[39mpredict(X_test)))\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reg\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:678\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    674\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    676\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 678\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    679\u001b[0m     X, y, accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse, y_numeric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    680\u001b[0m )\n\u001b[0;32m    682\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1145\u001b[0m     )\n\u001b[1;32m-> 1147\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1148\u001b[0m     X,\n\u001b[0;32m   1149\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1150\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1151\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1152\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1153\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1154\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m   1155\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1156\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1157\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1158\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1159\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1160\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[0;32m   1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    954\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    955\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    956\u001b[0m         )\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 959\u001b[0m         _assert_all_finite(\n\u001b[0;32m    960\u001b[0m             array,\n\u001b[0;32m    961\u001b[0m             input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    962\u001b[0m             estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    963\u001b[0m             allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    964\u001b[0m         )\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n\u001b[0;32m    125\u001b[0m     X,\n\u001b[0;32m    126\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[0;32m    127\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[0;32m    128\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[0;32m    129\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    130\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    131\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m     )\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "X_transform = FunctionTransformer(np.log1p).fit_transform(X)\n",
    "X_transformed = pd.DataFrame(X_transform,columns=X.columns)\n",
    "\n",
    "\n",
    "train(X_transformed,y,regression)\n",
    "train(X_transformed,y,knearestneighbour)\n",
    "train(X_transformed,y,decisiontree)\n",
    "train(X_transformed,y,randomForest)\n",
    "train(X_transformed,y,xgboost)\n",
    "train(X_transformed,y,gboost)\n",
    "train(X_transformed,y,catboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f7b383",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed =X_transformed.copy(deep=True)\n",
    "df_transformed['Price'] = y\n",
    "df_transformed.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "047baf96",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[103], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m X_transform \u001b[38;5;241m=\u001b[39m FunctionTransformer(cube)\u001b[38;5;241m.\u001b[39mfit_transform(X)\n\u001b[0;32m      6\u001b[0m X_transformed \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X_transform,columns\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m----> 9\u001b[0m train(X_transformed,y,regression)\n\u001b[0;32m     10\u001b[0m train(X_transformed,y,knearestneighbour)\n\u001b[0;32m     11\u001b[0m train(X_transformed,y,decisiontree)\n",
      "Cell \u001b[1;32mIn[92], line 71\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(X, y, modelType)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(X,y,modelType):\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# Split your dataset into train and test\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.33\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 71\u001b[0m     model \u001b[38;5;241m=\u001b[39m modelType(X_train, X_test, y_train, y_test)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "Cell \u001b[1;32mIn[92], line 24\u001b[0m, in \u001b[0;36mregression\u001b[1;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mregression\u001b[39m(X_train, X_test, y_train, y_test):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m## Baseline model\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     reg \u001b[38;5;241m=\u001b[39m linear_model\u001b[38;5;241m.\u001b[39mLinearRegression()\n\u001b[1;32m---> 24\u001b[0m     reg\u001b[38;5;241m.\u001b[39mfit(X_train,y_train)\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(metrics\u001b[38;5;241m.\u001b[39mr2_score(y_train,reg\u001b[38;5;241m.\u001b[39mpredict(X_train)), metrics\u001b[38;5;241m.\u001b[39mr2_score(y_test,reg\u001b[38;5;241m.\u001b[39mpredict(X_test)))\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reg\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:678\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    674\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    676\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 678\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    679\u001b[0m     X, y, accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse, y_numeric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    680\u001b[0m )\n\u001b[0;32m    682\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1145\u001b[0m     )\n\u001b[1;32m-> 1147\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1148\u001b[0m     X,\n\u001b[0;32m   1149\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1150\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1151\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1152\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1153\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1154\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m   1155\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1156\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1157\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1158\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1159\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1160\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[0;32m   1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    954\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    955\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    956\u001b[0m         )\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 959\u001b[0m         _assert_all_finite(\n\u001b[0;32m    960\u001b[0m             array,\n\u001b[0;32m    961\u001b[0m             input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    962\u001b[0m             estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    963\u001b[0m             allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    964\u001b[0m         )\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n\u001b[0;32m    125\u001b[0m     X,\n\u001b[0;32m    126\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[0;32m    127\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[0;32m    128\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[0;32m    129\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    130\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    131\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m     )\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def cube(X): return X**(0.333)\n",
    "\n",
    "X_transform = FunctionTransformer(cube).fit_transform(X)\n",
    "X_transformed = pd.DataFrame(X_transform,columns=X.columns)\n",
    "\n",
    "\n",
    "train(X_transformed,y,regression)\n",
    "train(X_transformed,y,knearestneighbour)\n",
    "train(X_transformed,y,decisiontree)\n",
    "train(X_transformed,y,randomForest)\n",
    "train(X_transformed,y,xgboost)\n",
    "train(X_transformed,y,gboost)\n",
    "train(X_transformed,y,catboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26401d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed =X_transformed.copy(deep=True)\n",
    "df_transformed['Price'] = y\n",
    "df_transformed.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "784124fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nPolynomialFeatures does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PolynomialFeatures\n\u001b[0;32m      2\u001b[0m poly \u001b[38;5;241m=\u001b[39m PolynomialFeatures(degree\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, include_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,interaction_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 4\u001b[0m X_transform \u001b[38;5;241m=\u001b[39m poly\u001b[38;5;241m.\u001b[39mfit_transform(X)\n\u001b[0;32m      5\u001b[0m X_transformed \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X_transform,columns\u001b[38;5;241m=\u001b[39mpoly\u001b[38;5;241m.\u001b[39mget_feature_names(X\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[0;32m      7\u001b[0m train(X_transformed,y,regression)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:915\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 915\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py:322\u001b[0m, in \u001b[0;36mPolynomialFeatures.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    306\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;124;03m    Compute number of output features.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;124;03m        Fitted transformer.\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 322\u001b[0m     _, n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdegree, Integral):\n\u001b[0;32m    325\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdegree \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minclude_bias:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    602\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 604\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    606\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    954\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    955\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    956\u001b[0m         )\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 959\u001b[0m         _assert_all_finite(\n\u001b[0;32m    960\u001b[0m             array,\n\u001b[0;32m    961\u001b[0m             input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    962\u001b[0m             estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    963\u001b[0m             allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    964\u001b[0m         )\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n\u001b[0;32m    125\u001b[0m     X,\n\u001b[0;32m    126\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[0;32m    127\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[0;32m    128\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[0;32m    129\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    130\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    131\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m     )\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nPolynomialFeatures does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False,interaction_only=False)\n",
    "\n",
    "X_transform = poly.fit_transform(X)\n",
    "X_transformed = pd.DataFrame(X_transform,columns=poly.get_feature_names(X.columns))\n",
    "\n",
    "train(X_transformed,y,regression)\n",
    "train(X_transformed,y,knearestneighbour)\n",
    "train(X_transformed,y,decisiontree)\n",
    "train(X_transformed,y,randomForest)\n",
    "train(X_transformed,y,xgboost)\n",
    "train(X_transformed,y,gboost)\n",
    "train(X_transformed,y,catboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cef40f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed =X_transformed.copy(deep=True)\n",
    "df_transformed['Price'] = y\n",
    "df_transformed.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16d84a2",
   "metadata": {},
   "source": [
    "## Adding Basic Time based Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b568c1e",
   "metadata": {},
   "source": [
    "## I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276c774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_of_day(hr):\n",
    "    '''\n",
    "    This function gives the time of day based on logic:\n",
    "        # 3-8 early_morning or 1\n",
    "        # 8-12 morning or 2\n",
    "        # 12-16 afternoon or 3\n",
    "        # 16-20 evening or 4\n",
    "        # 20-00 night or 5\n",
    "        # 00-3 late_night or 6\n",
    "        # invalid or 0\n",
    "    input:\n",
    "        hr\n",
    "    return: tuple\n",
    "        (timeOfDay,timeOfDay_encoded\n",
    "    '''\n",
    "    if hr in range(0,3) :\n",
    "        str_val = 'late_night'\n",
    "        val = 6\n",
    "    elif hr in range(20,23):\n",
    "        str_val = 'night'\n",
    "        val = 5\n",
    "    elif hr in range(16,20):\n",
    "        str_val = 'evening'\n",
    "        val = 4\n",
    "    elif hr in range(12,26):\n",
    "        str_val = 'after_noon'\n",
    "        val = 3\n",
    "    elif hr in range(8,12):\n",
    "        str_val = 'morning'\n",
    "        val = 2\n",
    "    elif hr in range(3,8):\n",
    "        str_val = 'early_morning'\n",
    "        val = 1\n",
    "    else:\n",
    "        str_val = 'invalid'\n",
    "        val = 0\n",
    "    return (str_val, val)\n",
    "\n",
    "            # 3-8 early_morning\n",
    "            # 8-12 morning\n",
    "            # 12-16 afternoon\n",
    "            # 16-20 evening\n",
    "            # 20-00 night\n",
    "            # 00-3 late_night\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2fdb909c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time_of_day' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[105], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdep_hr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDepartureDateTime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mhour\n\u001b[0;32m      2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marr_hr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArrivalDateTime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mhour\n\u001b[1;32m----> 4\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeparture_timeOfDay\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdep_hr\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: time_of_day(x)[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      5\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marrival_timeOfDay\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marr_hr\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: time_of_day(x)[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4521\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4525\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4526\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4527\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4528\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4529\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4628\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4629\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\u001b[38;5;28mself\u001b[39m, func, convert_dtype, args, kwargs)\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1076\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmap_infer(\n\u001b[0;32m   1077\u001b[0m             values,\n\u001b[0;32m   1078\u001b[0m             f,\n\u001b[0;32m   1079\u001b[0m             convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype,\n\u001b[0;32m   1080\u001b[0m         )\n\u001b[0;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[105], line 4\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdep_hr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDepartureDateTime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mhour\n\u001b[0;32m      2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marr_hr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArrivalDateTime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mhour\n\u001b[1;32m----> 4\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeparture_timeOfDay\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdep_hr\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: time_of_day(x)[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      5\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marrival_timeOfDay\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marr_hr\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: time_of_day(x)[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time_of_day' is not defined"
     ]
    }
   ],
   "source": [
    "df['dep_hr'] = df['DepartureDateTime'].dt.hour\n",
    "df['arr_hr'] = df['ArrivalDateTime'].dt.hour\n",
    "\n",
    "df['departure_timeOfDay'] = df['dep_hr'].apply(lambda x: time_of_day(x)[1])\n",
    "df['arrival_timeOfDay'] = df['arr_hr'].apply(lambda x: time_of_day(x)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d412c2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Price','DepartureDateTime','Duration_timedelta','ArrivalDateTime'])\n",
    "y = df['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b0c37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(X_transformed,y,regression)\n",
    "train(X_transformed,y,knearestneighbour)\n",
    "train(X_transformed,y,decisiontree)\n",
    "train(X_transformed,y,randomForest)\n",
    "train(X_transformed,y,xgboost)\n",
    "train(X_transformed,y,gboost)\n",
    "train(X_transformed,y,catboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b581e2",
   "metadata": {},
   "source": [
    "## II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded56c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_of_day(hr):\n",
    "    '''\n",
    "    This function gives the time of day based on logic:\n",
    "        # 3-8 early_morning or 1\n",
    "        # 8-12 morning or 2\n",
    "        # 12-16 afternoon or 3\n",
    "        # 16-20 evening or 4\n",
    "        # 20-00 night or 5\n",
    "        # 00-3 late_night or 6\n",
    "        # invalid or 0\n",
    "    input:\n",
    "        hr\n",
    "    return: tuple\n",
    "        (timeOfDay,timeOfDay_encoded\n",
    "    '''\n",
    "    if hr in range(0,3) :\n",
    "        str_val = 'late_night'\n",
    "        val = 6\n",
    "    elif hr in range(20,23):\n",
    "        str_val = 'night'\n",
    "        val = 5\n",
    "    elif hr in range(16,20):\n",
    "        str_val = 'evening'\n",
    "        val = 4\n",
    "    elif hr in range(12,26):\n",
    "        str_val = 'after_noon'\n",
    "        val = 3\n",
    "    elif hr in range(8,12):\n",
    "        str_val = 'morning'\n",
    "        val = 2\n",
    "    elif hr in range(3,8):\n",
    "        str_val = 'early_morning'\n",
    "        val = 1\n",
    "    else:\n",
    "        str_val = 'invalid'\n",
    "        val = 0\n",
    "    return (str_val, val)\n",
    "\n",
    "        # 3-8 early_morning\n",
    "        # 8-12 morning\n",
    "        # 12-16 afternoon\n",
    "        # 16-20 evening\n",
    "        # 20-00 night\n",
    "        # 00-3 late_night\n",
    "        \n",
    "df['dep_hr'] = df['DepartureDateTime'].dt.hour\n",
    "df['arr_hr'] = df['ArrivalDateTime'].dt.hour\n",
    "\n",
    "df['departure_timeOfDay'] = df['dep_hr'].apply(lambda x: time_of_day(x)[0])\n",
    "df['arrival_timeOfDay'] = df['arr_hr'].apply(lambda x: time_of_day(x)[0])\n",
    "\n",
    "df['departure_timeOfDay_encoded'] = df['dep_hr'].apply(lambda x: time_of_day(x)[1])\n",
    "df['arrival_timeOfDay_encoded'] = df['arr_hr'].apply(lambda x: time_of_day(x)[1])\n",
    "\n",
    "one_hot_cols = ['departure_timeOfDay','arrival_timeOfDay']\n",
    "df_oneHotEncoded = pd.get_dummies(df[one_hot_cols])\n",
    "\n",
    "new_df = pd.concat([df,df_oneHotEncoded],axis=1)\n",
    "\n",
    "new_df.drop(columns=one_hot_cols,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af8bae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df.drop(columns=['Price','DepartureDateTime','Duration_timedelta','ArrivalDateTime'])\n",
    "y = new_df['Price']\n",
    "\n",
    "print(X.columns)\n",
    "\n",
    "train(X_transformed,y,regression)\n",
    "train(X_transformed,y,knearestneighbour)\n",
    "train(X_transformed,y,decisiontree)\n",
    "\n",
    "model = train(X,y,randomForest)\n",
    "pd.DataFrame({'feature_names_in_':model.feature_names_in_,'feature_importances_':model.feature_importances_}).sort_values(by='feature_importances_',ascending=False)\n",
    "\n",
    "model = train(X,y,gboost)\n",
    "pd.DataFrame({'feature_names_in_':model.feature_names_in_,'feature_importances_':model.feature_importances_}).sort_values(by='feature_importances_',ascending=False)\n",
    "\n",
    "model = train(X,y,xgboost)\n",
    "importance_gain = model.get_booster().get_score(importance_type='gain')\n",
    "importance_cover = model.get_booster().get_score(importance_type='cover')\n",
    "importance_weight = model.get_booster().get_score(importance_type='weight')\n",
    "importance_total_gain = model.get_booster().get_score(importance_type='total_gain')\n",
    "importance_total_cover = model.get_booster().get_score(importance_type='total_cover')\n",
    "\n",
    "pd.DataFrame([importance_weight,importance_gain,importance_total_gain,importance_cover,importance_total_cover],index=['weight','gain','total_gain','cover','total_cover']).T\n",
    "\n",
    "model = train(X,y,catboost)\n",
    "pd.DataFrame({'feature_names_in_':X.columns,'feature_importances_':model.get_feature_importance()}).sort_values(by='feature_importances_',ascending=False)\n",
    "\n",
    "model = train(X,y,randomForest)\n",
    "pd.DataFrame({'feature_names_in_':model.feature_names_in_,'feature_importances_':model.feature_importances_}).sort_values(by='feature_importances_',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c269bf23",
   "metadata": {},
   "source": [
    "## III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "643a6f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_of_day(hr):\n",
    "    '''\n",
    "    This function gives the time of day based on logic:\n",
    "        # 3-8 early_morning or 1\n",
    "        # 8-12 morning or 2\n",
    "        # 12-16 afternoon or 3\n",
    "        # 16-20 evening or 4\n",
    "        # 20-00 night or 5\n",
    "        # 00-3 late_night or 6\n",
    "        # invalid or 0\n",
    "    input:\n",
    "        hr\n",
    "    return: tuple\n",
    "        (timeOfDay,timeOfDay_encoded\n",
    "    '''\n",
    "    if hr in range(0,3) :\n",
    "        str_val = 'late_night'\n",
    "        val = 6\n",
    "    elif hr in range(20,23):\n",
    "        str_val = 'night'\n",
    "        val = 5\n",
    "    elif hr in range(16,20):\n",
    "        str_val = 'evening'\n",
    "        val = 4\n",
    "    elif hr in range(12,26):\n",
    "        str_val = 'after_noon'\n",
    "        val = 3\n",
    "    elif hr in range(8,12):\n",
    "        str_val = 'morning'\n",
    "        val = 2\n",
    "    elif hr in range(3,8):\n",
    "        str_val = 'early_morning'\n",
    "        val = 1\n",
    "    else:\n",
    "        str_val = 'invalid'\n",
    "        val = 0\n",
    "    return (str_val, val)\n",
    "\n",
    "# 3-8 early_morning\n",
    "# 8-12 morning\n",
    "# 12-16 afternoon\n",
    "# 16-20 evening\n",
    "# 20-00 night\n",
    "# 00-3 late_night\n",
    "\n",
    "df['dep_hr'] = df['DepartureDateTime'].dt.hour\n",
    "df['arr_hr'] = df['ArrivalDateTime'].dt.hour\n",
    "\n",
    "df['dep_day_of_week'] = df['DepartureDateTime'].dt.day_of_week \n",
    "df['arr_day_of_week'] = df['ArrivalDateTime'].dt.day_of_week \n",
    "\n",
    "df['dep_weekday'] = np.where(df[\"dep_day_of_week\"].isin([5,6]),0,1)\n",
    "df['arr_weekday'] = np.where(df[\"arr_day_of_week\"].isin([5,6]),0,1)\n",
    "\n",
    "\n",
    "df['departure_timeOfDay'] = df['dep_hr'].apply(lambda x: time_of_day(x)[0])\n",
    "df['departure_timeOfDay_encoded'] = df['dep_hr'].apply(lambda x: time_of_day(x)[1])\n",
    "df['arrival_timeOfDay'] = df['arr_hr'].apply(lambda x: time_of_day(x)[0])\n",
    "df['arrival_timeOfDay_encoded'] = df['arr_hr'].apply(lambda x: time_of_day(x)[1])\n",
    "\n",
    "one_hot_cols = ['departure_timeOfDay','arrival_timeOfDay']\n",
    "df_oneHotEncoded = pd.get_dummies(df[one_hot_cols])\n",
    "new_df = pd.concat([df,df_oneHotEncoded],axis=1)\n",
    "new_df.drop(columns=one_hot_cols,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e7a84064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Total_Stops', 'Duration_min', 'Freq_encoded_Airline',\n",
      "       'Mean_encoded_Airline', 'Freq_encoded_Source',\n",
      "       'Freq_encoded_Destination', 'Freq_encoded_Route', 'Mean_encoded_Source',\n",
      "       'Mean_encoded_Destination', 'Mean_encoded_Route',\n",
      "       'Label_encoded_Airline', 'Label_encoded_Source',\n",
      "       'Label_encoded_Destination', 'Label_encoded_Route', 'dep_hr', 'arr_hr',\n",
      "       'dep_day_of_week', 'arr_day_of_week', 'dep_weekday', 'arr_weekday',\n",
      "       'departure_timeOfDay_encoded', 'arrival_timeOfDay_encoded',\n",
      "       'departure_timeOfDay_after_noon', 'departure_timeOfDay_early_morning',\n",
      "       'departure_timeOfDay_evening', 'departure_timeOfDay_late_night',\n",
      "       'departure_timeOfDay_morning', 'departure_timeOfDay_night',\n",
      "       'arrival_timeOfDay_after_noon', 'arrival_timeOfDay_early_morning',\n",
      "       'arrival_timeOfDay_evening', 'arrival_timeOfDay_late_night',\n",
      "       'arrival_timeOfDay_morning', 'arrival_timeOfDay_night'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[107], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m new_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrice\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(X\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m----> 6\u001b[0m train(X_transformed,y,regression)\n\u001b[0;32m      7\u001b[0m train(X_transformed,y,knearestneighbour)\n\u001b[0;32m      8\u001b[0m train(X_transformed,y,decisiontree)\n",
      "Cell \u001b[1;32mIn[92], line 71\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(X, y, modelType)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(X,y,modelType):\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# Split your dataset into train and test\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.33\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 71\u001b[0m     model \u001b[38;5;241m=\u001b[39m modelType(X_train, X_test, y_train, y_test)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "Cell \u001b[1;32mIn[92], line 24\u001b[0m, in \u001b[0;36mregression\u001b[1;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mregression\u001b[39m(X_train, X_test, y_train, y_test):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m## Baseline model\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     reg \u001b[38;5;241m=\u001b[39m linear_model\u001b[38;5;241m.\u001b[39mLinearRegression()\n\u001b[1;32m---> 24\u001b[0m     reg\u001b[38;5;241m.\u001b[39mfit(X_train,y_train)\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(metrics\u001b[38;5;241m.\u001b[39mr2_score(y_train,reg\u001b[38;5;241m.\u001b[39mpredict(X_train)), metrics\u001b[38;5;241m.\u001b[39mr2_score(y_test,reg\u001b[38;5;241m.\u001b[39mpredict(X_test)))\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reg\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:678\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    674\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    676\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 678\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    679\u001b[0m     X, y, accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse, y_numeric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    680\u001b[0m )\n\u001b[0;32m    682\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1145\u001b[0m     )\n\u001b[1;32m-> 1147\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1148\u001b[0m     X,\n\u001b[0;32m   1149\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1150\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1151\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1152\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1153\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1154\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m   1155\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1156\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1157\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1158\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1159\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1160\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[0;32m   1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    954\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    955\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    956\u001b[0m         )\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 959\u001b[0m         _assert_all_finite(\n\u001b[0;32m    960\u001b[0m             array,\n\u001b[0;32m    961\u001b[0m             input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    962\u001b[0m             estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    963\u001b[0m             allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    964\u001b[0m         )\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n\u001b[0;32m    125\u001b[0m     X,\n\u001b[0;32m    126\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[0;32m    127\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[0;32m    128\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[0;32m    129\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    130\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    131\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m     )\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "X = new_df.drop(columns=['Price','DepartureDateTime','Duration_timedelta','ArrivalDateTime'])\n",
    "y = new_df['Price']\n",
    "\n",
    "print(X.columns)\n",
    "\n",
    "train(X_transformed,y,regression)\n",
    "train(X_transformed,y,knearestneighbour)\n",
    "train(X_transformed,y,decisiontree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e50434",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df.drop(columns=['Price','DepartureDateTime','Duration_timedelta','ArrivalDateTime'])\n",
    "y = new_df['Price']\n",
    "\n",
    "print(X.columns)\n",
    "\n",
    "train(X_transformed,y,regression)\n",
    "train(X_transformed,y,knearestneighbour)\n",
    "train(X_transformed,y,decisiontree)\n",
    "\n",
    "model = train(X,y,randomForest)\n",
    "pd.DataFrame({'feature_names_in_':model.feature_names_in_,'feature_importances_':model.feature_importances_}).sort_values(by='feature_importances_',ascending=False)\n",
    "\n",
    "model = train(X,y,gboost)\n",
    "pd.DataFrame({'feature_names_in_':model.feature_names_in_,'feature_importances_':model.feature_importances_}).sort_values(by='feature_importances_',ascending=False)\n",
    "\n",
    "model = train(X,y,xgboost)\n",
    "importance_gain = model.get_booster().get_score(importance_type='gain')\n",
    "importance_cover = model.get_booster().get_score(importance_type='cover')\n",
    "importance_weight = model.get_booster().get_score(importance_type='weight')\n",
    "importance_total_gain = model.get_booster().get_score(importance_type='total_gain')\n",
    "importance_total_cover = model.get_booster().get_score(importance_type='total_cover')\n",
    "\n",
    "pd.DataFrame([importance_weight,importance_gain,importance_total_gain,importance_cover,importance_total_cover],index=['weight','gain','total_gain','cover','total_cover']).T\n",
    "\n",
    "model = train(X,y,catboost)\n",
    "pd.DataFrame({'feature_names_in_':X.columns,'feature_importances_':model.get_feature_importance()}).sort_values(by='feature_importances_',ascending=False)\n",
    "\n",
    "model = train(X,y,randomForest)\n",
    "pd.DataFrame({'feature_names_in_':model.feature_names_in_,'feature_importances_':model.feature_importances_}).sort_values(by='feature_importances_',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf27ccca",
   "metadata": {},
   "source": [
    "## IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "80b8b177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_of_day(hr):\n",
    "    '''\n",
    "    This function gives the time of day based on logic:\n",
    "        # 3-8 early_morning or 1\n",
    "        # 8-12 morning or 2\n",
    "        # 12-16 afternoon or 3\n",
    "        # 16-20 evening or 4\n",
    "        # 20-00 night or 5\n",
    "        # 00-3 late_night or 6\n",
    "        # invalid or 0\n",
    "    input:\n",
    "        hr\n",
    "    return: tuple\n",
    "        (timeOfDay,timeOfDay_encoded\n",
    "    '''\n",
    "    if hr in range(0,3) :\n",
    "        str_val = 'late_night'\n",
    "        val = 6\n",
    "    elif hr in range(20,23):\n",
    "        str_val = 'night'\n",
    "        val = 5\n",
    "    elif hr in range(16,20):\n",
    "        str_val = 'evening'\n",
    "        val = 4\n",
    "    elif hr in range(12,26):\n",
    "        str_val = 'after_noon'\n",
    "        val = 3\n",
    "    elif hr in range(8,12):\n",
    "        str_val = 'morning'\n",
    "        val = 2\n",
    "    elif hr in range(3,8):\n",
    "        str_val = 'early_morning'\n",
    "        val = 1\n",
    "    else:\n",
    "        str_val = 'invalid'\n",
    "        val = 0\n",
    "    return (str_val, val)\n",
    "# 3-8 early_morning\n",
    "# 8-12 morning\n",
    "# 12-16 afternoon\n",
    "# 16-20 evening\n",
    "# 20-00 night\n",
    "# 00-3 late_night\n",
    "\n",
    "\n",
    "\n",
    "df['dep_hr'] = df['DepartureDateTime'].dt.hour\n",
    "df['arr_hr'] = df['ArrivalDateTime'].dt.hour\n",
    "\n",
    "df['dep_month'] = df['DepartureDateTime'].dt.month\n",
    "df['dep_day_of_month'] = df['DepartureDateTime'].dt.day\n",
    "\n",
    "df['arr_month'] = df['ArrivalDateTime'].dt.month\n",
    "df['arr_day_of_month'] = df['ArrivalDateTime'].dt.day\n",
    "\n",
    "df['dep_day_of_week'] = df['DepartureDateTime'].dt.day_of_week \n",
    "df['arr_day_of_week'] = df['ArrivalDateTime'].dt.day_of_week \n",
    "\n",
    "df['dep_weekday'] = np.where(df[\"dep_day_of_week\"].isin([5,6]),0,1)\n",
    "df['arr_weekday'] = np.where(df[\"arr_day_of_week\"].isin([5,6]),0,1)\n",
    "\n",
    "\n",
    "df['departure_timeOfDay'] = df['dep_hr'].apply(lambda x: time_of_day(x)[0])\n",
    "df['departure_timeOfDay_encoded'] = df['dep_hr'].apply(lambda x: time_of_day(x)[1])\n",
    "df['arrival_timeOfDay'] = df['arr_hr'].apply(lambda x: time_of_day(x)[0])\n",
    "df['arrival_timeOfDay_encoded'] = df['arr_hr'].apply(lambda x: time_of_day(x)[1])\n",
    "\n",
    "one_hot_cols = ['departure_timeOfDay','arrival_timeOfDay']\n",
    "df_oneHotEncoded = pd.get_dummies(df[one_hot_cols])\n",
    "new_df = pd.concat([df,df_oneHotEncoded],axis=1)\n",
    "new_df.drop(columns=one_hot_cols,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "624768d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Total_Stops', 'Duration_min', 'Freq_encoded_Airline',\n",
      "       'Mean_encoded_Airline', 'Freq_encoded_Source',\n",
      "       'Freq_encoded_Destination', 'Freq_encoded_Route', 'Mean_encoded_Source',\n",
      "       'Mean_encoded_Destination', 'Mean_encoded_Route',\n",
      "       'Label_encoded_Airline', 'Label_encoded_Source',\n",
      "       'Label_encoded_Destination', 'Label_encoded_Route', 'dep_hr', 'arr_hr',\n",
      "       'dep_day_of_week', 'arr_day_of_week', 'dep_weekday', 'arr_weekday',\n",
      "       'departure_timeOfDay_encoded', 'arrival_timeOfDay_encoded', 'dep_month',\n",
      "       'dep_day_of_month', 'arr_month', 'arr_day_of_month',\n",
      "       'departure_timeOfDay_after_noon', 'departure_timeOfDay_early_morning',\n",
      "       'departure_timeOfDay_evening', 'departure_timeOfDay_late_night',\n",
      "       'departure_timeOfDay_morning', 'departure_timeOfDay_night',\n",
      "       'arrival_timeOfDay_after_noon', 'arrival_timeOfDay_early_morning',\n",
      "       'arrival_timeOfDay_evening', 'arrival_timeOfDay_late_night',\n",
      "       'arrival_timeOfDay_morning', 'arrival_timeOfDay_night'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[109], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m new_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrice\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(X\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m----> 6\u001b[0m train(X_transformed,y,regression)\n\u001b[0;32m      7\u001b[0m train(X_transformed,y,knearestneighbour)\n\u001b[0;32m      8\u001b[0m train(X_transformed,y,decisiontree)\n",
      "Cell \u001b[1;32mIn[92], line 71\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(X, y, modelType)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(X,y,modelType):\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# Split your dataset into train and test\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.33\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 71\u001b[0m     model \u001b[38;5;241m=\u001b[39m modelType(X_train, X_test, y_train, y_test)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "Cell \u001b[1;32mIn[92], line 24\u001b[0m, in \u001b[0;36mregression\u001b[1;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mregression\u001b[39m(X_train, X_test, y_train, y_test):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m## Baseline model\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     reg \u001b[38;5;241m=\u001b[39m linear_model\u001b[38;5;241m.\u001b[39mLinearRegression()\n\u001b[1;32m---> 24\u001b[0m     reg\u001b[38;5;241m.\u001b[39mfit(X_train,y_train)\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(metrics\u001b[38;5;241m.\u001b[39mr2_score(y_train,reg\u001b[38;5;241m.\u001b[39mpredict(X_train)), metrics\u001b[38;5;241m.\u001b[39mr2_score(y_test,reg\u001b[38;5;241m.\u001b[39mpredict(X_test)))\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reg\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:678\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    674\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    676\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 678\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    679\u001b[0m     X, y, accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse, y_numeric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    680\u001b[0m )\n\u001b[0;32m    682\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1145\u001b[0m     )\n\u001b[1;32m-> 1147\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1148\u001b[0m     X,\n\u001b[0;32m   1149\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1150\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1151\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1152\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1153\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1154\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m   1155\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1156\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1157\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1158\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1159\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1160\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[0;32m   1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    954\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    955\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    956\u001b[0m         )\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 959\u001b[0m         _assert_all_finite(\n\u001b[0;32m    960\u001b[0m             array,\n\u001b[0;32m    961\u001b[0m             input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    962\u001b[0m             estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    963\u001b[0m             allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    964\u001b[0m         )\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n\u001b[0;32m    125\u001b[0m     X,\n\u001b[0;32m    126\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[0;32m    127\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[0;32m    128\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[0;32m    129\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    130\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    131\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m     )\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "X = new_df.drop(columns=['Price','DepartureDateTime','Duration_timedelta','ArrivalDateTime'])\n",
    "y = new_df['Price']\n",
    "\n",
    "print(X.columns)\n",
    "\n",
    "train(X_transformed,y,regression)\n",
    "train(X_transformed,y,knearestneighbour)\n",
    "train(X_transformed,y,decisiontree)\n",
    "\n",
    "\n",
    "model = train(X,y,randomForest)\n",
    "pd.DataFrame({'feature_names_in_':model.feature_names_in_,'feature_importances_':model.feature_importances_}).sort_values(by='feature_importances_',ascending=False)\n",
    "\n",
    "model = train(X,y,gboost)\n",
    "pd.DataFrame({'feature_names_in_':model.feature_names_in_,'feature_importances_':model.feature_importances_}).sort_values(by='feature_importances_',ascending=False)\n",
    "\n",
    "model = train(X,y,xgboost)\n",
    "importance_gain = model.get_booster().get_score(importance_type='gain')\n",
    "importance_cover = model.get_booster().get_score(importance_type='cover')\n",
    "importance_weight = model.get_booster().get_score(importance_type='weight')\n",
    "importance_total_gain = model.get_booster().get_score(importance_type='total_gain')\n",
    "importance_total_cover = model.get_booster().get_score(importance_type='total_cover')\n",
    "\n",
    "pd.DataFrame([importance_weight,importance_gain,importance_total_gain,importance_cover,importance_total_cover],index=['weight','gain','total_gain','cover','total_cover']).T\n",
    "\n",
    "model = train(X,y,catboost)\n",
    "pd.DataFrame({'feature_names_in_':X.columns,'feature_importances_':model.get_feature_importance()}).sort_values(by='feature_importances_',ascending=False)\n",
    "\n",
    "model = train(X,y,randomForest)\n",
    "pd.DataFrame({'feature_names_in_':model.feature_names_in_,'feature_importances_':model.feature_importances_}).sort_values(by='feature_importances_',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d8fd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df.drop(columns=['Price','DepartureDateTime','Duration_timedelta','ArrivalDateTime'])\n",
    "y = new_df['Price']\n",
    "\n",
    "print(X.columns)\n",
    "\n",
    "train(X_transformed,y,regression)\n",
    "train(X_transformed,y,knearestneighbour)\n",
    "train(X_transformed,y,decisiontree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d2ac3d93",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nRandomForestRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[110], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m train(X,y,randomForest)\n\u001b[0;32m      2\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_names_in_\u001b[39m\u001b[38;5;124m'\u001b[39m:model\u001b[38;5;241m.\u001b[39mfeature_names_in_,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_importances_\u001b[39m\u001b[38;5;124m'\u001b[39m:model\u001b[38;5;241m.\u001b[39mfeature_importances_})\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_importances_\u001b[39m\u001b[38;5;124m'\u001b[39m,ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[92], line 71\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(X, y, modelType)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(X,y,modelType):\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# Split your dataset into train and test\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.33\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 71\u001b[0m     model \u001b[38;5;241m=\u001b[39m modelType(X_train, X_test, y_train, y_test)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "Cell \u001b[1;32mIn[92], line 42\u001b[0m, in \u001b[0;36mrandomForest\u001b[1;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrandomForest\u001b[39m(X_train, X_test, y_train, y_test):\n\u001b[0;32m     41\u001b[0m     random_regressor \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,min_samples_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 42\u001b[0m     random_regressor\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(metrics\u001b[38;5;241m.\u001b[39mr2_score(y_train,random_regressor\u001b[38;5;241m.\u001b[39mpredict(X_train)),metrics\u001b[38;5;241m.\u001b[39mr2_score(y_test,random_regressor\u001b[38;5;241m.\u001b[39mpredict(X_test)))\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m random_regressor\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:348\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 348\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    349\u001b[0m     X, y, multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mDTYPE\n\u001b[0;32m    350\u001b[0m )\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1145\u001b[0m     )\n\u001b[1;32m-> 1147\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1148\u001b[0m     X,\n\u001b[0;32m   1149\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1150\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1151\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1152\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1153\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1154\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m   1155\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1156\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1157\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1158\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1159\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1160\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[0;32m   1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    954\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    955\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    956\u001b[0m         )\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 959\u001b[0m         _assert_all_finite(\n\u001b[0;32m    960\u001b[0m             array,\n\u001b[0;32m    961\u001b[0m             input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    962\u001b[0m             estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    963\u001b[0m             allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    964\u001b[0m         )\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n\u001b[0;32m    125\u001b[0m     X,\n\u001b[0;32m    126\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[0;32m    127\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[0;32m    128\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[0;32m    129\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    130\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    131\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m     )\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nRandomForestRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "model = train(X,y,randomForest)\n",
    "pd.DataFrame({'feature_names_in_':model.feature_names_in_,'feature_importances_':model.feature_importances_}).sort_values(by='feature_importances_',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec19cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train(X,y,gboost)\n",
    "pd.DataFrame({'feature_names_in_':model.feature_names_in_,'feature_importances_':model.feature_importances_}).sort_values(by='feature_importances_',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b54b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train(X,y,xgboost)\n",
    "importance_gain = model.get_booster().get_score(importance_type='gain')\n",
    "importance_cover = model.get_booster().get_score(importance_type='cover')\n",
    "importance_weight = model.get_booster().get_score(importance_type='weight')\n",
    "importance_total_gain = model.get_booster().get_score(importance_type='total_gain')\n",
    "importance_total_cover = model.get_booster().get_score(importance_type='total_cover')\n",
    "\n",
    "pd.DataFrame([importance_weight,importance_gain,importance_total_gain,importance_cover,importance_total_cover],index=['weight','gain','total_gain','cover','total_cover']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d30eb412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9212487478368616 0.8573681986959675\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_names_in_</th>\n",
       "      <th>feature_importances_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mean_encoded_Route</td>\n",
       "      <td>28.144868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>dep_day_of_month</td>\n",
       "      <td>9.272157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mean_encoded_Airline</td>\n",
       "      <td>8.210206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>arr_month</td>\n",
       "      <td>7.588095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>dep_month</td>\n",
       "      <td>7.221982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>arr_day_of_month</td>\n",
       "      <td>6.846200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Duration_min</td>\n",
       "      <td>5.801596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Freq_encoded_Airline</td>\n",
       "      <td>3.987141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Freq_encoded_Route</td>\n",
       "      <td>3.362545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Label_encoded_Route</td>\n",
       "      <td>2.674448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>arr_hr</td>\n",
       "      <td>2.281524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Label_encoded_Airline</td>\n",
       "      <td>2.113649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dep_hr</td>\n",
       "      <td>1.567123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dep_day_of_week</td>\n",
       "      <td>1.362522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total_Stops</td>\n",
       "      <td>1.274083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>arr_day_of_week</td>\n",
       "      <td>0.903812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>dep_weekday</td>\n",
       "      <td>0.832407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Label_encoded_Source</td>\n",
       "      <td>0.816411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>arrival_timeOfDay_encoded</td>\n",
       "      <td>0.741004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mean_encoded_Source</td>\n",
       "      <td>0.648299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Label_encoded_Destination</td>\n",
       "      <td>0.640759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Freq_encoded_Destination</td>\n",
       "      <td>0.511801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Freq_encoded_Source</td>\n",
       "      <td>0.483458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mean_encoded_Destination</td>\n",
       "      <td>0.437875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>departure_timeOfDay_encoded</td>\n",
       "      <td>0.423548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>arr_weekday</td>\n",
       "      <td>0.364050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>departure_timeOfDay_after_noon</td>\n",
       "      <td>0.294475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>departure_timeOfDay_morning</td>\n",
       "      <td>0.186233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>departure_timeOfDay_evening</td>\n",
       "      <td>0.179617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>arrival_timeOfDay_late_night</td>\n",
       "      <td>0.162726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>arrival_timeOfDay_after_noon</td>\n",
       "      <td>0.159230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>arrival_timeOfDay_early_morning</td>\n",
       "      <td>0.138371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>arrival_timeOfDay_night</td>\n",
       "      <td>0.127984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>arrival_timeOfDay_morning</td>\n",
       "      <td>0.097451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>departure_timeOfDay_early_morning</td>\n",
       "      <td>0.055482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>arrival_timeOfDay_evening</td>\n",
       "      <td>0.048677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>departure_timeOfDay_night</td>\n",
       "      <td>0.024719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>departure_timeOfDay_late_night</td>\n",
       "      <td>0.013473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    feature_names_in_  feature_importances_\n",
       "9                  Mean_encoded_Route             28.144868\n",
       "23                   dep_day_of_month              9.272157\n",
       "3                Mean_encoded_Airline              8.210206\n",
       "24                          arr_month              7.588095\n",
       "22                          dep_month              7.221982\n",
       "25                   arr_day_of_month              6.846200\n",
       "1                        Duration_min              5.801596\n",
       "2                Freq_encoded_Airline              3.987141\n",
       "6                  Freq_encoded_Route              3.362545\n",
       "13                Label_encoded_Route              2.674448\n",
       "15                             arr_hr              2.281524\n",
       "10              Label_encoded_Airline              2.113649\n",
       "14                             dep_hr              1.567123\n",
       "16                    dep_day_of_week              1.362522\n",
       "0                         Total_Stops              1.274083\n",
       "17                    arr_day_of_week              0.903812\n",
       "18                        dep_weekday              0.832407\n",
       "11               Label_encoded_Source              0.816411\n",
       "21          arrival_timeOfDay_encoded              0.741004\n",
       "7                 Mean_encoded_Source              0.648299\n",
       "12          Label_encoded_Destination              0.640759\n",
       "5            Freq_encoded_Destination              0.511801\n",
       "4                 Freq_encoded_Source              0.483458\n",
       "8            Mean_encoded_Destination              0.437875\n",
       "20        departure_timeOfDay_encoded              0.423548\n",
       "19                        arr_weekday              0.364050\n",
       "26     departure_timeOfDay_after_noon              0.294475\n",
       "30        departure_timeOfDay_morning              0.186233\n",
       "28        departure_timeOfDay_evening              0.179617\n",
       "35       arrival_timeOfDay_late_night              0.162726\n",
       "32       arrival_timeOfDay_after_noon              0.159230\n",
       "33    arrival_timeOfDay_early_morning              0.138371\n",
       "37            arrival_timeOfDay_night              0.127984\n",
       "36          arrival_timeOfDay_morning              0.097451\n",
       "27  departure_timeOfDay_early_morning              0.055482\n",
       "34          arrival_timeOfDay_evening              0.048677\n",
       "31          departure_timeOfDay_night              0.024719\n",
       "29     departure_timeOfDay_late_night              0.013473"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = train(X,y,catboost)\n",
    "pd.DataFrame({'feature_names_in_':X.columns,'feature_importances_':model.get_feature_importance()}).sort_values(by='feature_importances_',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b549b508",
   "metadata": {},
   "outputs": [],
   "source": [
    "## After doing Time-based feature Engineering we found best model to be xgboost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5cbb2025",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid non-printable character U+200B (291284002.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[113], line 7\u001b[1;36m\u001b[0m\n\u001b[1;33m    ​\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid non-printable character U+200B\n"
     ]
    }
   ],
   "source": [
    "model = train(X,y,xgboost)\n",
    "importance_gain = model.get_booster().get_score(importance_type='gain')\n",
    "importance_cover = model.get_booster().get_score(importance_type='cover')\n",
    "importance_weight = model.get_booster().get_score(importance_type='weight')\n",
    "importance_total_gain = model.get_booster().get_score(importance_type='total_gain')\n",
    "importance_total_cover = model.get_booster().get_score(importance_type='total_cover')\n",
    "​\n",
    "pd.DataFrame([importance_weight,importance_gain,importance_total_gain,importance_cover,importance_total_cover],index=['weight','gain','total_gain','cover','total_cover']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23327ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vif= sklearn_vif(exogs=X.columns, data=X).sort_values(by='VIF',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fe9171",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99537c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_cols = ['Total_Stops', 'Duration_min', 'Freq_encoded_Airline',\n",
    "       'Mean_encoded_Airline', \n",
    "#             'Freq_encoded_Source',\n",
    "       'Freq_encoded_Destination', 'Freq_encoded_Route', \n",
    "#             'Mean_encoded_Source',\n",
    "#        'Mean_encoded_Destination',\n",
    "            'Mean_encoded_Route',\n",
    "       'Label_encoded_Airline', 'Label_encoded_Source',\n",
    "       'Label_encoded_Destination', 'Label_encoded_Route', 'dep_hr', 'arr_hr',\n",
    "#        'departure_timeOfDay_encoded',\n",
    "            'arrival_timeOfDay_encoded',\n",
    "       'dep_day_of_week', 'arr_day_of_week', 'dep_weekday', 'arr_weekday',\n",
    "       'dep_month', 'dep_day_of_month', \n",
    "#             'arr_month', \n",
    "#             'arr_day_of_month',\n",
    "       'departure_timeOfDay_after_noon', \n",
    "#             'departure_timeOfDay_early_morning',\n",
    "#        'departure_timeOfDay_evening',\n",
    "            'departure_timeOfDay_late_night',\n",
    "       'departure_timeOfDay_morning', 'departure_timeOfDay_night',\n",
    "       'arrival_timeOfDay_after_noon', 'arrival_timeOfDay_early_morning',\n",
    "       'arrival_timeOfDay_evening', \n",
    "#             'arrival_timeOfDay_late_night',\n",
    "#        'arrival_timeOfDay_morning', \n",
    "#             'arrival_timeOfDay_night'\n",
    "           ]\n",
    "\n",
    "X =X[vif_cols]\n",
    "\n",
    "df_vif= sklearn_vif(exogs=X.columns, data=X).sort_values(by='VIF',ascending=False)\n",
    "df_vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fae658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train(X[vif_cols],y,xgboost)\n",
    "\n",
    "importance_gain = model.get_booster().get_score(importance_type='gain')\n",
    "importance_cover = model.get_booster().get_score(importance_type='cover')\n",
    "importance_weight = model.get_booster().get_score(importance_type='weight')\n",
    "importance_total_gain = model.get_booster().get_score(importance_type='total_gain')\n",
    "importance_total_cover = model.get_booster().get_score(importance_type='total_cover')\n",
    "\n",
    "pd.DataFrame([importance_weight,importance_gain,importance_total_gain,importance_cover,importance_total_cover],index=['weight','gain','total_gain','cover','total_cover']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2358a3",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0c54f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb4b419",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "Xgboost_reg = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaea693",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Xgboost_reg\n",
    "X = X[vif_cols]\n",
    "y = y\n",
    "number_of_cross_validation = 5\n",
    "\n",
    "def basic_cross_validation(estimator,X,y,number_of_cross_validation=5):\n",
    "    scores = cross_validate(estimator, X, y, cv=number_of_cross_validation,\n",
    "                             scoring=('r2', 'neg_mean_squared_error'),\n",
    "                             return_train_score=True)\n",
    "\n",
    "    print(scores['train_r2'])\n",
    "    print(scores['train_r2'].mean())\n",
    "\n",
    "    print(scores['test_r2'])\n",
    "    print(scores['test_r2'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728169cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3a32f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_cross_validation(CatBoostRegressor(verbose=False),X[vif_cols],y,number_of_cross_validation=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dae625",
   "metadata": {},
   "source": [
    "#### Actions taken in feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcf277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_of_day(hr):\n",
    "    '''\n",
    "    This function gives the time of day based on logic:\n",
    "        # 3-8 early_morning or 1\n",
    "        # 8-12 morning or 2\n",
    "        # 12-16 afternoon or 3\n",
    "        # 16-20 evening or 4\n",
    "        # 20-00 night or 5\n",
    "        # 00-3 late_night or 6\n",
    "        # invalid or 0\n",
    "    input:\n",
    "        hr\n",
    "    return: tuple\n",
    "        (timeOfDay,timeOfDay_encoded\n",
    "    '''\n",
    "    if hr in range(0,3) :\n",
    "        str_val = 'late_night'\n",
    "        val = 6\n",
    "    elif hr in range(20,23):\n",
    "        str_val = 'night'\n",
    "        val = 5\n",
    "    elif hr in range(16,20):\n",
    "        str_val = 'evening'\n",
    "        val = 4\n",
    "    elif hr in range(12,26):\n",
    "        str_val = 'after_noon'\n",
    "        val = 3\n",
    "    elif hr in range(8,12):\n",
    "        str_val = 'morning'\n",
    "        val = 2\n",
    "    elif hr in range(3,8):\n",
    "        str_val = 'early_morning'\n",
    "        val = 1\n",
    "    else:\n",
    "        str_val = 'invalid'\n",
    "        val = 0\n",
    "    return (str_val, val)\n",
    "\n",
    "\n",
    "def time_based_feature_Engineering(df):\n",
    "\n",
    "    df['dep_hr'] = df['DepartureDateTime'].dt.hour\n",
    "    df['arr_hr'] = df['ArrivalDateTime'].dt.hour\n",
    "\n",
    "    df['dep_month'] = df['DepartureDateTime'].dt.month\n",
    "    df['dep_day_of_month'] = df['DepartureDateTime'].dt.day\n",
    "\n",
    "    df['arr_month'] = df['ArrivalDateTime'].dt.month\n",
    "    df['arr_day_of_month'] = df['ArrivalDateTime'].dt.day\n",
    "\n",
    "    df['dep_day_of_week'] = df['DepartureDateTime'].dt.day_of_week \n",
    "    df['arr_day_of_week'] = df['ArrivalDateTime'].dt.day_of_week \n",
    "\n",
    "    df['dep_weekday'] = np.where(df[\"dep_day_of_week\"].isin([5,6]),0,1)\n",
    "    df['arr_weekday'] = np.where(df[\"arr_day_of_week\"].isin([5,6]),0,1)\n",
    "\n",
    "\n",
    "    df['departure_timeOfDay'] = df['dep_hr'].apply(lambda x: time_of_day(x)[0])\n",
    "    df['departure_timeOfDay_encoded'] = df['dep_hr'].apply(lambda x: time_of_day(x)[1])\n",
    "    df['arrival_timeOfDay'] = df['arr_hr'].apply(lambda x: time_of_day(x)[0])\n",
    "    df['arrival_timeOfDay_encoded'] = df['arr_hr'].apply(lambda x: time_of_day(x)[1])\n",
    "\n",
    "    one_hot_cols = ['departure_timeOfDay','arrival_timeOfDay']\n",
    "    df_oneHotEncoded = pd.get_dummies(df[one_hot_cols])\n",
    "    new_df = pd.concat([df,df_oneHotEncoded],axis=1)\n",
    "    \n",
    "    drop_cols = [\n",
    "                'DepartureDateTime',\n",
    "                'Duration_timedelta',\n",
    "                'ArrivalDateTime',\n",
    "                'Freq_encoded_Source',\n",
    "                'Mean_encoded_Source',\n",
    "                'Mean_encoded_Destination',\n",
    "                'departure_timeOfDay_encoded',\n",
    "                'arr_month', \n",
    "                'arr_day_of_month',\n",
    "                'departure_timeOfDay_early_morning',\n",
    "                'departure_timeOfDay_evening',\n",
    "                'arrival_timeOfDay_late_night',\n",
    "                'arrival_timeOfDay_morning', \n",
    "                'arrival_timeOfDay_night']\n",
    "    \n",
    "    new_df.drop(columns=one_hot_cols,inplace=True)\n",
    "    new_df.drop(columns=drop_cols,inplace=True)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97beec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = time_based_feature_Engineering(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4355efc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"FinalData.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffa8e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b382930",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df.drop(columns='Price')\n",
    "y = final_df['Price']\n",
    "model = train(X,y,xgboost)\n",
    "\n",
    "importance_gain = model.get_booster().get_score(importance_type='gain')\n",
    "importance_cover = model.get_booster().get_score(importance_type='cover')\n",
    "importance_weight = model.get_booster().get_score(importance_type='weight')\n",
    "importance_total_gain = model.get_booster().get_score(importance_type='total_gain')\n",
    "importance_total_cover = model.get_booster().get_score(importance_type='total_cover')\n",
    "\n",
    "pd.DataFrame([importance_weight,importance_gain,importance_total_gain,importance_cover,importance_total_cover],index=['weight','gain','total_gain','cover','total_cover']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6ef3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af496080",
   "metadata": {},
   "source": [
    "## Paramter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aca9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1b7c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"learning_rate\" : [0.1,0.2,0.3,0.5,],\n",
    "    \"max_depth\" : [4,5,6,7],\n",
    "    \"n_estimators\" : [100,200,300,400,500]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6ae528",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = RandomizedSearchCV(XGBRegressor(),param_grid,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a9a879",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = reg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba17a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f50247",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ae2ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_cross_validation(model.best_estimator_,X,y,number_of_cross_validation=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ec70f709",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CatBoostRegressor' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[114], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.33\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m xgboost_regressor \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m      3\u001b[0m xgboost_regressor\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(metrics\u001b[38;5;241m.\u001b[39mr2_score(y_train,xgboost_regressor\u001b[38;5;241m.\u001b[39mpredict(X_train)),metrics\u001b[38;5;241m.\u001b[39mr2_score(y_test,xgboost_regressor\u001b[38;5;241m.\u001b[39mpredict(X_test)))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CatBoostRegressor' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "xgboost_regressor = model.best_estimator_\n",
    "xgboost_regressor.fit(X_train, y_train)\n",
    "print(metrics.r2_score(y_train,xgboost_regressor.predict(X_train)),metrics.r2_score(y_test,xgboost_regressor.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "37928214",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"learning_rate\" : [0.2,0.21,0.29],\n",
    "    \"n_estimators\" : [95,100,105]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "30a3bb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = GridSearchCV(XGBRegressor(),param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e13f9307",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 45 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n    return f(**kwargs)\n           ^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py\", line 761, in fit\n    train_dmatrix, evals = _wrap_evaluation_matrices(\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py\", line 286, in _wrap_evaluation_matrices\n    train_dmatrix = create_dmatrix(\n                    ^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py\", line 775, in <lambda>\n    create_dmatrix=lambda **kwargs: DMatrix(nthread=self.n_jobs, **kwargs),\n                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n    return f(**kwargs)\n           ^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 616, in __init__\n    handle, feature_names, feature_types = dispatch_data_backend(\n                                           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 772, in dispatch_data_backend\n    return _from_pandas_df(data, enable_categorical, missing, threads,\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 312, in _from_pandas_df\n    data, feature_names, feature_types = _transform_pandas_df(\n                                         ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 262, in _transform_pandas_df\n    elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n                                   ^^^^^^^^^^^^^\nAttributeError: module 'pandas' has no attribute 'Int64Index'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[117], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m reg\u001b[38;5;241m.\u001b[39mfit(X,y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    870\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    873\u001b[0m     )\n\u001b[1;32m--> 875\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_score)\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    408\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m     )\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    417\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    424\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 45 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n    return f(**kwargs)\n           ^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py\", line 761, in fit\n    train_dmatrix, evals = _wrap_evaluation_matrices(\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py\", line 286, in _wrap_evaluation_matrices\n    train_dmatrix = create_dmatrix(\n                    ^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py\", line 775, in <lambda>\n    create_dmatrix=lambda **kwargs: DMatrix(nthread=self.n_jobs, **kwargs),\n                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 506, in inner_f\n    return f(**kwargs)\n           ^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 616, in __init__\n    handle, feature_names, feature_types = dispatch_data_backend(\n                                           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 772, in dispatch_data_backend\n    return _from_pandas_df(data, enable_categorical, missing, threads,\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 312, in _from_pandas_df\n    data, feature_names, feature_types = _transform_pandas_df(\n                                         ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 262, in _transform_pandas_df\n    elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n                                   ^^^^^^^^^^^^^\nAttributeError: module 'pandas' has no attribute 'Int64Index'\n"
     ]
    }
   ],
   "source": [
    "model = reg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af02de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a0c1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18aa0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_cross_validation(model.best_estimator_,X,y,number_of_cross_validation=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801b3009",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "xgboost_regressor = model.best_estimator_\n",
    "xgboost_regressor.fit(X_train, y_train)\n",
    "print(metrics.r2_score(y_train,xgboost_regressor.predict(X_train)),metrics.r2_score(y_test,xgboost_regressor.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7324e652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBRegressor( learning_rate=0.21, max_depth=6,  n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b353b868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "602368d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../models/xgboost.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[118], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models/xgboost.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      2\u001b[0m         pickle\u001b[38;5;241m.\u001b[39mdump(xgboost_regressor,file)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m     )\n\u001b[1;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../models/xgboost.pickle'"
     ]
    }
   ],
   "source": [
    "with open('../models/xgboost.pickle','wb') as file:\n",
    "        pickle.dump(xgboost_regressor,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4691e79b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24dd53c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cfdcfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030b76d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
